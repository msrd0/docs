searchState.loadedDescShard("ffmpeg_sys_next", 0, "@defgroup lavu_adler32 Adler-32 @ingroup lavu_hash …\nMessage types used by …\n@}\nA reference to a data buffer.\nThis structure contains the parameters describing the …\n&lt; MPEG-1 4:2:0, JPEG 4:2:0, H.263 4:2:0\n&lt; MPEG-2/4 4:2:0, H.264 default for 4:2:0\n&lt; Not part of ABI\n&lt; ITU-R 601, SMPTE 274M 296M S314M(DV 4:1:1), mpeg2 4:2:2\n&lt; ITU-R BT2020\n&lt; also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 …\n&lt; also FCC Title 47 Code of Federal Regulations 73.682 …\n&lt; also ITU-R BT1361 / IEC 61966-2-4 / SMPTE RP 177 Annex B\n&lt; EBU Tech. 3213-E (nothing there) / one of JEDEC P22 …\n&lt; colour filters using Illuminant C\n&lt; Not part of ABI\n&lt; also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 …\n&lt; identical to above, also called “SMPTE C” even …\n&lt; SMPTE ST 428-1 (CIE 1931 XYZ)\n&lt; SMPTE ST 431-2 (2011) / DCI P3\n&lt; SMPTE ST 432-1 (2010) / P3 D65 / Display P3\nFull range content.\nNarrow or limited range content.\n&lt; Not part of ABI\n&lt; ITU-R BT2020 constant luminance system\n&lt; ITU-R BT2020 non-constant luminance system\n&lt; also ITU-R BT601-6 625 / ITU-R BT1358 625 / ITU-R BT1700 …\n&lt; also ITU-R BT1361 / IEC 61966-2-4 xvYCC709 / derived in …\n&lt; Chromaticity-derived constant luminance system\n&lt; Chromaticity-derived non-constant luminance system\n&lt; FCC Title 47 Code of Federal Regulations 73.682 (a)(20)\n&lt; ITU-R BT.2100-0, ICtCp\n&lt; SMPTE ST 2128, IPT-C2\n&lt; Not part of ABI\n&lt; reserved for future use by ITU-T and ISO/IEC just like …\n&lt; order of coefficients is actually GBR, also IEC …\n&lt; also ITU-R BT601-6 525 / ITU-R BT1358 525 / ITU-R BT1700 …\n&lt; SMPTE 2085, Y’D’zD’x\n&lt; derived from 170M primaries and D65 white point, 170M is …\n&lt; used by Dirac / VC-2 and H.264 FRext, see ITU-T SG16\n&lt; YCgCo-R, even addition of bits\n&lt; YCgCo-R, odd addition of bits\n&lt; ARIB STD-B67, known as “Hybrid log-gamma”\n&lt; ITU-R BT1361 Extended Colour Gamut\n&lt; ITU-R BT2020 for 10-bit system\n&lt; ITU-R BT2020 for 12-bit system\n&lt; also ITU-R BT1361\n&lt; also ITU-R BT470M / ITU-R BT1700 625 PAL &amp; SECAM\n&lt; also ITU-R BT470BG\n&lt; IEC 61966-2-1 (sRGB or sYCC)\n&lt; IEC 61966-2-4\n&lt; “Linear transfer characteristics”\n&lt; “Logarithmic transfer characteristic (100:1 range)”\n&lt; “Logarithmic transfer characteristic (100 * Sqrt(10) : …\n&lt; Not part of ABI\n&lt; also ITU-R BT601-6 525 or 625 / ITU-R BT1358 525 or 625 …\n&lt; SMPTE ST 2084 for 10-, 12-, 14- and 16-bit systems\n&lt; SMPTE ST 428-1\nThis structure describes the bitrate properties of an …\n@defgroup lavu_crc32 CRC @ingroup lavu_hash CRC (Cyclic …\n@defgroup lavu_audio_channels Audio channels @ingroup …\nAn AVChannelCustom defines a single channel within a …\nAn AVChannelLayout holds information about the channel …\nDetails about which channels are present in this layout. …\nLocation of chroma samples.\nDescribe the class of an AVClass context structure. That …\nAVCodec.\nmain external API structure. New fields can be added to …\nThis struct describes the properties of a single codec …\nIdentify the syntax and semantics of the bitstream. The …\nPrivate context used for internal data.\nThis struct describes the properties of an encoded stream.\nChromaticity coordinates of the source primaries. These …\nVisual content value range.\nYUV colorspace type. These values match the ones defined …\nColor Transfer Characteristic. These values match the ones …\n&lt; discard all\n&lt; discard all bidirectional frames\n&lt; discard useless packets like 0 size packets in avi\n&lt; discard nothing\n&lt; discard all non intra frames\n&lt; discard all frames except keyframes\n&lt; discard all non reference\nDRM device.\nDRM frame descriptor.\nDRM layer descriptor.\nDRM object descriptor.\nDRM plane descriptor.\nMessage types used by …\nStructure describes basic parameters of the device.\nList of devices.\n@}\n@ingroup lavc_decoding\nThis structure describes optional metadata relevant to a …\nPossible downmix types.\nThe duration of a video can be estimated through various …\n&lt; all automatic conversions enabled\n&lt; all automatic conversions disabled\n&lt; Duration estimated from bitrate (less accurate)\n&lt; Duration accurately estimated from PTSes\n&lt; Duration estimated from a stream with a known duration\nCallback for writing or reading from a FIFO, passed to …\nFilter definition. This defines the pads a filter …\nA filterchain is a list of filter specifications.\nAn instance of a filter\nLists of formats / etc. supported by an end of a link.\nA parsed representation of a filtergraph segment.\nA linked-list of the inputs/outputs of the filter chain.\nA link between two filters. This contains pointers to the …\nParameters of a filter’s input or output pad.\nParameters describing a filter to be created in a …\nThe state of the following union is determined by …\nFormat I/O context. New fields can be added to the end …\nThis structure describes decoded (raw) audio or video data.\nStructure to hold side data for an AVFrame.\n@defgroup lavu_frame AVFrame @ingroup lavu_data\n@defgroup lavu_hmac HMAC @ingroup lavu_crypto @{\n@defgroup lavc_hwaccel AVHWAccel\nThis struct aggregates all the (hardware/vendor-specific) …\nThis struct describes the constraints on hardware frames …\nThis struct describes a set or pool of “hardware” …\n@example ffhash.c This example is a simple command line …\nBytestream IO Context. New public fields can be added with …\nDifferent data types that can be returned via the AVIO …\nDescribes single entry of the directory.\nDirectory entry types.\nCallback for checking whether to abort blocking functions. …\nA point in the output bytestream where a demuxer can start …\nA point in the output bytestream where the underlying …\nHeader data; this needs to be present for the stream to be …\nA point in the output bytestream where a decoder can start …\nTrailer data, which doesn’t contain actual content, but …\nThis is any, unlabelled data. It can either be a muxer not …\n@addtogroup lavf_decoding @{\nContext structure for the Lagged Fibonacci PRNG. The exact …\n&lt; Opaque data information usually sparse\n&lt; Opaque data information usually continuous\n&lt; Usually treated as AVMEDIA_TYPE_DATA\n@addtogroup lavu_media Media Type @brief Media Type\nAVOption\nMay be set as default_val for AV_OPT_TYPE_FLAG_ARRAY …\nA single allowed range of values, or a single allowed …\nList of AVOptionRange structs.\nAn option type determines:\nNative access only, except when documented otherwise. the …\n@addtogroup lavf_encoding @{\nThis structure stores compressed data. It is typically …\nThis structure stores auxiliary information for decoding, …\n@defgroup lavc_packet_side_data AVPacketSideData\nPan Scan area. This specifies the area which should be …\n@defgroup lavc_parsing Frame parsing @{\n@} @} @defgroup lavu_picture Image related\nDescriptor that unambiguously describes how the bits of a …\nPixel format.\nThis structure contains the data a format has to probe a …\nThis structure supplies correlation between a packet …\nAVProfile.\nNew fields can be added to the end with minor version …\nRational number (pair of numerator and denominator).\nStructure describing a single Region Of Interest.\nReplayGain information (see …\nRounding methods.\n&lt; full parsing and repack\n&lt; full parsing and repack of the first frame only, only …\n&lt; full parsing and repack with timestamp and position …\n&lt; Only parse headers, do not repack.\n&lt; full parsing and interpolation of timestamps for frames …\nAudio sample formats\nThis struct describes the properties of a side data type. …\nStereo 3D type: this structure describes how two videos …\nList of possible primary eyes.\nList of possible 3D Types\nList of possible view types.\nStream structure. New fields can be added to the end with …\nAVStreamGroupLCEVC is meant to define the relation between …\nAVStreamGroupTileGrid holds information on how to combine …\nAn @ref nb_tiles sized array of offsets in pixels from the …\nGroup type-specific parameters\n@}\n@}\n@file @brief Public header for libavutil XTEA algorithm …\nGet volume/mute messages.\nGet volume/mute messages.\nMute control messages.\nDummy message.\nRequest pause/play.\nRequest pause/play.\nVolume control message.\nMute control messages.\nRequest pause/play.\nMute control messages.\nRepaint request message.\nWindow size change message.\n&lt; Not part of ABI\nKeep a reference to the frame. If the frame if …\nDo not check for format changes.\nImmediately push the frame to the output.\nThe audio is represented as the decomposition of the sound …\nThe channel order does not correspond to any other …\nThe native channel order, i.e. the channels are in the …\nOnly the channel count is specified, without any further …\nRange of channels between AV_CHAN_AMBISONIC_BASE and …\nRange of channels between AV_CHAN_AMBISONIC_BASE and …\nSee above.\nSee above.\nSee above.\nSee above.\n&lt;  +90 degrees, Lss, SiL\n&lt;  -90 degrees, Rss, SiR\nStereo downmix.\nSee above.\nSee above.\nSee above.\nSee above.\nSee above.\n&lt; +110 degrees, Lvs, TpLS\n&lt; -110 degrees, Rvs, TpRS\nChannel contains data, but its position is unknown.\nChannel is empty can be safely skipped.\nSee above.\nSee above.\n&lt; not part of ABI/API\n&lt; AVChannelLayout, terminated by {0}\n&lt; AVColorRange, terminated by AVCOL_RANGE_UNSPECIFIED\n&lt; AVColorSpace, terminated by AVCOL_SPC_UNSPECIFIED\n&lt; AVRational, terminated by {0, 0}\n&lt; AVPixelFormat, terminated by AV_PIX_FMT_NONE\n&lt; AVSampleFormat, terminated by AV_SAMPLE_FMT_NONE\n&lt; int, terminated by 0\nThe codec supports this format by some ad-hoc method.\nThe codec supports this format via the hw_device_ctx …\nThe codec supports this format via the hw_frames_ctx …\nThe codec supports this format by some internal method.\nDummy null audio codec, useful mainly for development and …\n&lt; Dummy codec for streams containing only metadata …\n&lt; as in Berlin toast format\n&lt; preferred ID for decoding MPEG audio layer 1, 2 or 3\n&lt; <em>FAKE</em> codec to indicate a raw MPEG-2 TS stream (only used …\n&lt; preferred ID for MPEG-1/2 video decoding\n&lt; <em>FAKE</em> codec to indicate a MPEG-4 Systems stream (only …\n&lt; codec_id is not known (like AV_CODEC_ID_NONE) but lavf …\n&lt; Contain timestamp estimated through PCR of program …\n&lt; raw UTF-8 text\nDummy null video codec, useful mainly for development and …\n&lt; Passthrough codec, AVFrames wrapped in AVPacket\nBuffer fullness status messages.\nBuffer readable/writable.\nBuffer fullness status messages.\nBuffer readable/writable.\nCreate window buffer message.\nDestroy window buffer message.\nDisplay window buffer message.\nMute state change message.\nDummy message.\nPrepare window buffer message.\nVolume level change message.\n&lt; Lt/Rt 2-channel downmix, Dolby Pro Logic II compatible.\n&lt; Lo/Ro 2-channel downmix (Stereo).\n&lt; Lt/Rt 2-channel downmix, Dolby Surround compatible.\n&lt; Number of downmix types. Not part of ABI.\n&lt; Not indicated.\nThe maximum number of layers/planes in a DRM frame.\n&lt; Use auto-selected escaping mode.\n&lt; Use backslash escaping.\n&lt; Use single-quote escaping.\n&lt; Use XML non-markup character data escaping.\n&lt; Bottom coded first, bottom displayed first\n&lt; Bottom coded first, top displayed first\n&lt; Top coded first, bottom displayed first\n&lt; Top coded_first, top displayed first\nApply the maximum possible cropping, even if it requires …\nATSC A53 Part 4 Closed Captions. A53 CC bitstream is …\nActive Format Description data consisting of a single byte …\nAmbient viewing environment metadata, as defined by H.274.\nThis side data must be associated with an audio frame and …\nContent light level (based on CTA-861.3). This payload …\nBounding boxes for object detection and classification, as …\nThis side data contains a 3x3 transformation matrix …\nParsed Dolby Vision metadata, suitable for passing to a …\nDolby Vision RPU raw data, suitable for passing to x265 or …\nMetadata relevant to a downmix procedure. The data is the …\nHDR dynamic metadata associated with a video frame. The …\nHDR Vivid dynamic metadata associated with a video frame. …\nFilm grain parameters for a frame, described by …\nThe GOP timecode in 25 bit timecode format. Data format is …\nThe data contains an ICC profile as an opaque octet buffer …\nRaw LCEVC payload data, as a uint8_t array, with NAL …\nMastering display metadata associated with a video frame. …\nThe data is the AVMatrixEncoding enum defined in …\nMotion vectors exported by some codecs (on demand through …\nThe data is the AVPanScan struct defined in libavcodec.\nRegions Of Interest, the data is an array of …\nReplayGain information in the form of the AVReplayGain …\nTimecode which conforms to SMPTE ST 12-1. The data is an …\nUser data unregistered metadata associated with a video …\nRecommmends skipping the specified number of samples. This …\nThe data represents the AVSphericalMapping structure …\nStereoscopic 3d metadata. The data is the AVStereo3D …\nEncoding parameters for a video frame, as described by …\nProvide encoder-specific hinting information about …\nThis side data must be associated with a video frame. The …\nThe mapping must be direct.  That is, there must not be …\nThe mapped frame will be overwritten completely in …\nThe mapping must be readable.\nThe mapping must be writeable.\nTransfer the data from the queried hw frame.\nTransfer the data to the queried hw frame.\nAccept to parse a value without a key; the key will then …\nUnderlying C type is a uint8_t* that is either NULL or …\nUnderlying C type is int.\nUnderlying C type is AVChannelLayout.\nUnderlying C type is uint8_t[4].\nSpecial option type for declaring named constants. Does …\nUnderlying C type is AVDictionary*.\nUnderlying C type is double.\nUnderlying C type is int64_t.\nUnderlying C type is unsigned int.\nMay be combined with another regular option type to …\nUnderlying C type is float.\nUnderlying C type is two consecutive integers.\nUnderlying C type is int.\nUnderlying C type is int64_t.\nUnderlying C type is enum AVPixelFormat.\nUnderlying C type is AVRational.\nUnderlying C type is enum AVSampleFormat.\nUnderlying C type is a uint8_t* that is either NULL or …\nUnderlying C type is unsigned int.\nUnderlying C type is uint64_t.\nUnderlying C type is AVRational.\n&lt; coded as bottom field\n&lt; coded as frame\n&lt; coded as top field\n&lt; unknown\n&lt; Bi-dir predicted\n&lt; BI type\n&lt; Intra\n&lt; Undefined\n&lt; Predicted\n&lt; S(GMC)-VOP MPEG-4\n&lt; Switching Intra\n&lt; Switching Predicted\n&lt; packed BGR 8:8:8, 32bpp, XBGRXBGR…   X=unused/undefined\n&lt; packed RGB 8:8:8, 32bpp, XRGBXRGB…   X=unused/undefined\n&lt; packed ABGR 8:8:8:8, 32bpp, ABGRABGR…\n&lt; packed ARGB 8:8:8:8, 32bpp, ARGBARGB…\n&lt; packed AYUV 4:4:4,64bpp (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; packed AYUV 4:4:4,64bpp (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; bayer, BGBG..(odd line), GRGR..(even line), 16-bit …\n&lt; bayer, BGBG..(odd line), GRGR..(even line), 16-bit …\n&lt; bayer, BGBG..(odd line), GRGR..(even line), 8-bit samples\n&lt; bayer, GBGB..(odd line), RGRG..(even line), 16-bit …\n&lt; bayer, GBGB..(odd line), RGRG..(even line), 16-bit …\n&lt; bayer, GBGB..(odd line), RGRG..(even line), 8-bit samples\n&lt; bayer, GRGR..(odd line), BGBG..(even line), 16-bit …\n&lt; bayer, GRGR..(odd line), BGBG..(even line), 16-bit …\n&lt; bayer, GRGR..(odd line), BGBG..(even line), 8-bit samples\n&lt; bayer, RGRG..(odd line), GBGB..(even line), 16-bit …\n&lt; bayer, RGRG..(odd line), GBGB..(even line), 16-bit …\n&lt; bayer, RGRG..(odd line), GBGB..(even line), 8-bit samples\n&lt; packed BGR 8:8:8, 32bpp, BGRXBGRX…   X=unused/undefined\n&lt; packed RGB 8:8:8, 24bpp, BGRBGR…\n&lt; packed RGB 1:2:1 bitstream,  4bpp, (msb)1B 2G 1R(lsb), a …\n&lt; packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), …\n&lt; packed BGR 4:4:4, 16bpp, (msb)4X 4B 4G 4R(lsb), …\n&lt; packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte …\n&lt; packed RGB 16:16:16, 48bpp, 16B, 16G, 16R, the 2-byte …\n&lt; packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb)\n&lt; packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), …\n&lt; packed BGR 5:5:5, 16bpp, (msb)1X 5B 5G 5R(lsb), …\n&lt; packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), …\n&lt; packed BGR 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), …\n&lt; packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb)\n&lt; packed BGRA 8:8:8:8, 32bpp, BGRABGRA…\n&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the …\n&lt; packed RGBA 16:16:16:16, 64bpp, 16B, 16G, 16R, 16A, the …\nHW acceleration through CUDA. data[i] contain CUdeviceptr …\nHardware surfaces for Direct3D11.\n&lt; HW decoding through Direct3D11 via old API, Picture.data[…\nHardware surfaces for Direct3D 12.\nDRM-managed buffers exposed through PRIME buffer sharing.\n&lt; HW decoding through DXVA2, Picture.data[3] contains a …\n&lt; planar GBRA 4:4:4:4 32bpp\n&lt; planar GBR 4:4:4:4 40bpp, big-endian\n&lt; planar GBR 4:4:4:4 40bpp, little-endian\n&lt; planar GBR 4:4:4:4 48bpp, big-endian\n&lt; planar GBR 4:4:4:4 48bpp, little-endian\n&lt; planar GBR 4:4:4:4 56bpp, big-endian\n&lt; planar GBR 4:4:4:4 56bpp, little-endian\n&lt; planar GBRA 4:4:4:4 64bpp, big-endian\n&lt; planar GBRA 4:4:4:4 64bpp, little-endian\n&lt; IEEE-754 single precision planar GBRA 4:4:4:4, 128bpp, …\n&lt; IEEE-754 single precision planar GBRA 4:4:4:4, 128bpp, …\n&lt; planar GBR 4:4:4 24bpp\n&lt; planar GBR 4:4:4 30bpp, big-endian\n&lt; planar GBR 4:4:4 30bpp, little-endian\n&lt; planar GBR 4:4:4 36bpp, big-endian\n&lt; planar GBR 4:4:4 36bpp, little-endian\n&lt; planar GBR 4:4:4 42bpp, big-endian\n&lt; planar GBR 4:4:4 42bpp, little-endian\n&lt; planar GBR 4:4:4 48bpp, big-endian\n&lt; planar GBR 4:4:4 48bpp, little-endian\n&lt; planar GBR 4:4:4 27bpp, big-endian\n&lt; planar GBR 4:4:4 27bpp, little-endian\n&lt; IEEE-754 single precision planar GBR 4:4:4,     96bpp, …\n&lt; IEEE-754 single precision planar GBR 4:4:4,     96bpp, …\n&lt;        Y        , 10bpp, big-endian\n&lt;        Y        , 10bpp, little-endian\n&lt;        Y        , 12bpp, big-endian\n&lt;        Y        , 12bpp, little-endian\n&lt;        Y        , 14bpp, big-endian\n&lt;        Y        , 14bpp, little-endian\n&lt;        Y        , 16bpp, big-endian\n&lt;        Y        , 16bpp, little-endian\n&lt;        Y        ,  8bpp\n&lt;        Y        , 9bpp, big-endian\n&lt;        Y        , 9bpp, little-endian\n&lt; IEEE-754 single precision Y, 32bpp, big-endian\n&lt; IEEE-754 single precision Y, 32bpp, little-endian\n&lt; hardware decoding through MediaCodec\nHW acceleration though MMAL, data[3] contains a pointer to …\n&lt;        Y        ,  1bpp, 0 is black, 1 is white, in each …\n&lt;        Y        ,  1bpp, 0 is white, 1 is black, in each …\n&lt; number of pixel formats, DO NOT USE THIS if you want to …\n&lt; planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for …\n&lt; interleaved chroma YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample …\n&lt; interleaved chroma YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample …\n&lt; interleaved chroma YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample …\n&lt; as above, but U and V bytes are swapped\n&lt; planar YUV 4:4:4, 24bpp, 1 plane for Y and 1 plane for …\n&lt; as above, but U and V bytes are swapped\nHardware surfaces for OpenCL.\n&lt; like NV12, with 10bpp per component, data in the high …\n&lt; like NV12, with 10bpp per component, data in the high …\n&lt; like NV12, with 12bpp per component, data in the high …\n&lt; like NV12, with 12bpp per component, data in the high …\n&lt; like NV12, with 16bpp per component, big-endian\n&lt; like NV12, with 16bpp per component, little-endian\n&lt; interleaved chroma YUV 4:2:2, 20bpp, data in the high …\n&lt; interleaved chroma YUV 4:2:2, 20bpp, data in the high …\n&lt; interleaved chroma YUV 4:2:2, 24bpp, data in the high …\n&lt; interleaved chroma YUV 4:2:2, 24bpp, data in the high …\n&lt; interleaved chroma YUV 4:2:2, 32bpp, big-endian\n&lt; interleaved chroma YUV 4:2:2, 32bpp, little-endian\n&lt; interleaved chroma YUV 4:4:4, 30bpp, data in the high …\n&lt; interleaved chroma YUV 4:4:4, 30bpp, data in the high …\n&lt; interleaved chroma YUV 4:4:4, 36bpp, data in the high …\n&lt; interleaved chroma YUV 4:4:4, 36bpp, data in the high …\n&lt; interleaved chroma YUV 4:4:4, 48bpp, big-endian\n&lt; interleaved chroma YUV 4:4:4, 48bpp, little-endian\n&lt; 8 bits with AV_PIX_FMT_RGB32 palette\nHW acceleration through QSV, data[3] contains a pointer to …\n&lt; packed RGB 8:8:8, 32bpp, RGBXRGBX…   X=unused/undefined\n&lt; packed RGB 8:8:8, 24bpp, RGBRGB…\n&lt; packed RGB 1:2:1 bitstream,  4bpp, (msb)1R 2G 1B(lsb), a …\n&lt; packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), …\n&lt; packed RGB 4:4:4, 16bpp, (msb)4X 4R 4G 4B(lsb), …\n&lt; packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte …\n&lt; packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, the 2-byte …\n&lt; packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)\n&lt; packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), …\n&lt; packed RGB 5:5:5, 16bpp, (msb)1X 5R 5G 5B(lsb), …\n&lt; packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), …\n&lt; packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), …\n&lt; packed RGB 3:3:2,  8bpp, (msb)3R 3G 2B(lsb)\n&lt; packed RGBA 8:8:8:8, 32bpp, RGBARGBA…\n&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the …\n&lt; packed RGBA 16:16:16:16, 64bpp, 16R, 16G, 16B, 16A, the …\n&lt; IEEE-754 half precision packed RGBA 16:16:16:16, 64bpp, …\n&lt; IEEE-754 half precision packed RGBA 16:16:16:16, 64bpp, …\n&lt; IEEE-754 single precision packed RGBA 32:32:32:32, …\n&lt; IEEE-754 single precision packed RGBA 32:32:32:32, …\n&lt; IEEE-754 single precision packed RGB 32:32:32, 96bpp, …\n&lt; IEEE-754 single precision packed RGB 32:32:32, 96bpp, …\n&lt; packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1\n&lt; packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3\nHardware acceleration through VA-API, data[3] contains a …\n&lt; HW acceleration through VDPAU, Picture.data[3] contains …\n&lt; hardware decoding through Videotoolbox\nVulkan hardware images.\n&lt; packed VUYA 4:4:4, 32bpp, VUYAVUYA…\n&lt; packed VUYX 4:4:4, 32bpp, Variant of VUYA where alpha …\n&lt; packed BGR 10:10:10, 30bpp, (msb)2X 10B 10G 10R(lsb), …\n&lt; packed BGR 10:10:10, 30bpp, (msb)2X 10B 10G 10R(lsb), …\n&lt; packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), …\n&lt; packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), …\n&lt; packed XVYU 4:4:4, 32bpp, (msb)2X 10V 10Y 10U(lsb), …\n&lt; packed XVYU 4:4:4, 32bpp, (msb)2X 10V 10Y 10U(lsb), …\n&lt; packed XVYU 4:4:4, 48bpp, data in the high bits, zeros …\n&lt; packed XVYU 4:4:4, 48bpp, data in the high bits, zeros …\n&lt; packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the …\n&lt; packed XYZ 4:4:4, 36 bpp, (msb) 12X, 12Y, 12Z (lsb), the …\n&lt; packed YUV 4:2:2 like YUYV422, 20bpp, data in the high …\n&lt; packed YUV 4:2:2 like YUYV422, 20bpp, data in the high …\n&lt; packed YUV 4:2:2 like YUYV422, 24bpp, data in the high …\n&lt; packed YUV 4:2:2 like YUYV422, 24bpp, data in the high …\n&lt; 16 bits gray, 16 bits alpha (big-endian)\n&lt; 16 bits gray, 16 bits alpha (little-endian)\n&lt; 8 bits gray, 8 bits alpha\n&lt; planar YUV 4:1:0,  9bpp, (1 Cr &amp; Cb sample per 4x4 Y …\n&lt; planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y …\n&lt; planar YUV 4:2:0, 12bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0, 15bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0, 15bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0,18bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0,18bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0,21bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0,21bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0, 24bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0, 24bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0, 13.5bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:0, 13.5bpp, (1 Cr &amp; Cb sample per 2x2 Y …\n&lt; planar YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2, 20bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2,28bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2,28bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2, 32bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2, 32bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2, 18bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2, 18bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:4:0 (1 Cr &amp; Cb sample per 1x2 Y samples)\n&lt; planar YUV 4:4:0,20bpp, (1 Cr &amp; Cb sample per 1x2 Y …\n&lt; planar YUV 4:4:0,20bpp, (1 Cr &amp; Cb sample per 1x2 Y …\n&lt; planar YUV 4:4:0,24bpp, (1 Cr &amp; Cb sample per 1x2 Y …\n&lt; planar YUV 4:4:0,24bpp, (1 Cr &amp; Cb sample per 1x2 Y …\n&lt; planar YUV 4:4:4, 24bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4, 30bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4, 30bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4,42bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4,42bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4, 48bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4, 48bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4, 27bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4, 27bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:2:0, 20bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A …\n&lt; planar YUV 4:2:0 25bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A …\n&lt; planar YUV 4:2:0 25bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A …\n&lt; planar YUV 4:2:0 40bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A …\n&lt; planar YUV 4:2:0 40bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A …\n&lt; planar YUV 4:2:0 22.5bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; …\n&lt; planar YUV 4:2:0 22.5bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; …\n&lt; planar YUV 4:2:2 24bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:2:2 30bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:2:2 30bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2,24bpp, (1 Cr &amp; Cb sample per 2x1 Y …\n&lt; planar YUV 4:2:2 48bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:2:2 48bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:2:2 27bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:2:2 27bpp, (1 Cr &amp; Cb sample per 2x1 Y &amp; A …\n&lt; planar YUV 4:4:4 32bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:4:4 40bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:4:4 40bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4,36bpp, (1 Cr &amp; Cb sample per 1x1 Y …\n&lt; planar YUV 4:4:4 64bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:4:4 64bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:4:4 36bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:4:4 36bpp, (1 Cr &amp; Cb sample per 1x1 Y &amp; A …\n&lt; planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y …\n&lt; planar YUV 4:2:0, 12bpp, full scale (JPEG), deprecated …\n&lt; planar YUV 4:2:2, 16bpp, full scale (JPEG), deprecated …\n&lt; planar YUV 4:4:0 full scale (JPEG), deprecated in favor …\n&lt; planar YUV 4:4:4, 24bpp, full scale (JPEG), deprecated …\n&lt; packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr\n&lt; packed YUV 4:2:2, 16bpp, Y0 Cr Y1 Cb\nATSC A53 Part 4 Closed Captions. This metadata should be …\nActive Format Description data consisting of a single byte …\nAmbient viewing environment metadata, as defined by H.274. …\nThis side data should be associated with an audio stream …\nContent light level (based on CTA-861.3). This metadata …\nThis side data corresponds to the AVCPBProperties struct.\nThis side data contains a 3x3 transformation matrix …\nDOVI configuration ref: …\nHDR10+ dynamic metadata associated with a video frame. The …\nThis side data contains encryption info for how to decrypt …\nThis side data is encryption initialization data. The …\nThis side data contains an integer value representing the …\nThe number of pixels to discard from the …\nAn AV_PKT_DATA_H263_MB_INFO side data packet contains a …\nIAMF Demixing Info Parameter Data associated with the …\nIAMF Mix Gain Parameter Data associated with the audio …\nIAMF Recon Gain Info Parameter Data associated with the …\nICC profile data consisting of an opaque octet buffer …\nAn AV_PKT_DATA_JP_DUALMONO side data packet indicates that …\nRaw LCEVC payload data, as a uint8_t array, with NAL …\nMastering display metadata (based on SMPTE-2086:2014). …\nData found in BlockAdditional element of matroska …\nA list of zero terminated key/value strings. There is no …\nMPEGTS stream ID as uint8_t, this is required to pass the …\nThe number of side data types. This is not part of the …\nThe AV_PKT_DATA_NEW_EXTRADATA is used to notify the codec …\nAn AV_PKT_DATA_PALETTE side data packet contains exactly …\nAn AV_PKT_DATA_PARAM_CHANGE side data packet is laid out …\nProducer Reference Time data corresponding to the …\nThis side data contains quality related information from …\nThis side data should be associated with an audio stream …\nTimecode which conforms to SMPTE ST 12-1:2014. The data is …\nRecommmends skipping the specified number of samples @code …\nThis side data should be associated with a video stream …\nThis side data should be associated with a video stream …\nA list of zero terminated key/value strings. There is no …\nSubtitle event position @code u32le x1 u32le y1 u32le x2 …\nThe optional first identifier line of a WebVTT cue.\nThe optional settings (rendering instructions) that …\nLeft eye.\nNeither eye.\nRight eye\n&lt; Round toward -infinity.\n&lt; Round away from zero.\n&lt; Round to nearest and halfway cases away from zero.\nFlag telling rescaling functions to pass <code>INT64_MIN</code>/<code>MAX</code> …\n&lt; Round toward +infinity.\n&lt; Round toward zero.\n&lt; double\n&lt; double, planar\n&lt; float\n&lt; float, planar\n&lt; Number of sample formats. DO NOT USE if linking …\n&lt; signed 16 bits\n&lt; signed 16 bits, planar\n&lt; signed 32 bits\n&lt; signed 32 bits, planar\n&lt; signed 64 bits\n&lt; signed 64 bits, planar\n&lt; unsigned 8 bits\n&lt; unsigned 8 bits, planar\nThe side data type can be used in stream-global structures.\nMultiple instances of this side data type can be …\nVideo is not stereoscopic (and metadata has to be there).\nViews are packed in a checkerboard-like structure per …\nViews are packed per column.\nViews are alternated temporally.\nViews are packed per line, as if interlaced.\nViews are next to each other.\nViews are next to each other, but when upscaling apply a …\nViews are on top of each other.\nVideo is stereoscopic but the packing is unspecified.\nFrame contains only the left view.\nFrame contains two packed views.\nFrame contains only the right view.\nContent is unspecified.\nPerform non-blocking operation. If this flag is set, send …\n&lt; timecode wraps after 24 hours\n&lt; negative time values are allowed\n&lt; timecode is drop frame\n@defgroup lavc_fft FFT functions @ingroup lavc_misc\nNumber of channel orders, not part of ABI/API\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\n@ingroup lavc_encoding\nFormatted text, the ass field must be set by the decoder …\n&lt; A bitmap, pict will be set\nPlain text, the text field must be set by the decoder and …\n&lt; not part of API/ABI\n&lt; not part of API/ABI\n&lt; not part of API/ABI\n&lt; SoX Resampler\n&lt; SW Resampler\n&lt; Blackman Nuttall windowed sinc\n&lt; Cubic\n&lt; Kaiser windowed sinc\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nDithering algorithms\nResampling Engines\nResampling Filter Types\nFlags for frame cropping.\nFlags to apply to frame mappings.\n@defgroup lavfi_buffersrc Buffer source API @ingroup lavfi …\n@file API-specific header for AV_HWDEVICE_TYPE_DRM.\n&lt; Time of last access in microseconds since unix epoch, -1 …\nFilter activation function.\nWhich multithreading methods are in use by the codec.\nSame as track_gain, but for the whole album.\nSame as track_peak, but for the whole album,\nAlternative comma-separated names.\nVideo decoding only. Certain video codecs support …\n&lt; swr options to use for the auto-inserted aresample …\nUsed for AV_OPT_TYPE_FLAG_ARRAY options. May be NULL.\n0 terminated ASS/SSA compatible event line. The …\nFor streams with AV_DISPOSITION_ATTACHED_PIC disposition, …\n&lt; default audio codec\nForced audio codec. This allows forcing a specific …\nForced audio codec_id. Demuxing: Set by user.\nAudio preload in microseconds. Note, not all formats …\nType of service that the audio stream conveys.\nAdd an index entry into a sorted list. Update the entry if …\nAdd two rationals. @param b First rational @param c Second …\nAdd a value to a timestamp.\nCalculate the Adler32 checksum of a buffer.\nAllocate an AVAES context.\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVAES context.\n@defgroup lavu_aes AES @ingroup lavu_crypto @{\nRead data and append it to the current content of the …\nAppend path component to the existing path. Path separator …\nPrint arguments following specified format into a large …\nAllocate an AVAudioFifo.\nDrain data from an AVAudioFifo.\nFree an AVAudioFifo.\nPeek data from an AVAudioFifo.\nPeek data from an AVAudioFifo.\nRead data from an AVAudioFifo.\nReallocate an AVAudioFifo.\nReset the AVAudioFifo buffer.\nGet the current number of samples in the AVAudioFifo …\nGet the current number of samples in the AVAudioFifo …\nWrite data to an AVAudioFifo.\nDecode a base64-encoded string.\nEncode data to base64 and null-terminate.\nThread safe basename. @param path the string to parse, on …\n0th order modified bessel function of the first kind.\nAllocate an AVBlowfish context.\nEncrypt or decrypt a buffer using a previously initialized …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVBlowfish context.\nGet the next two numbers generated by a Box-Muller Gaussian\nAppend data to a print buffer.\nAppend char c n times to a print buffer.\nReset the string to “” but keep internal allocated …\nEscape the content in src and append it to dstbuf.\nFinalize a print buffer.\nAllocate bytes in the buffer for external use.\nInit a print buffer.\nInit a print buffer using a pre-existing buffer.\nAppend a formatted date and time to a print buffer.\nAppend a formatted string to a print buffer.\nAllocate an AVBuffer of the given size using av_malloc().\nSame as av_buffer_alloc(), except the returned buffer will …\nCreate an AVBuffer from an existing array.\nDefault free callback, which calls av_free() on the buffer …\n@return the opaque parameter set by av_buffer_create.\n@return 1 if the caller may write to the data referred to …\nCreate a writable reference from a given buffer reference, …\nQuery the original opaque parameter of an allocated buffer …\nAllocate a new AVBuffer, reusing an old buffer from the …\nAllocate and initialize a buffer pool.\nAllocate and initialize a buffer pool with a more complex …\nMark the pool as being available for freeing. It will …\nReallocate a given buffer.\nCreate a new reference to an AVBuffer.\nEnsure dst refers to the same data as src.\nFree a given reference and automatically free the buffer …\nGet a frame with filtered data from sink and put it in …\nGet a frame with filtered data from sink and put it in …\nSame as av_buffersink_get_frame(), but with the ability to …\n@defgroup lavfi_buffersink_accessors Buffer sink accessors …\nSet the frame size for an audio buffer sink.\nAdd a frame to the buffer source.\nAdd a frame to the buffer source.\nClose the buffer source after EOF.\nGet the number of failed requests.\nAllocate a new AVBufferSrcParameters instance. It should …\nInitialize the buffersrc or abuffersrc filter with the …\nAdd a frame to the buffer source.\nAllocate a memory block for an array with av_mallocz().\nAllocate an AVCAMELLIA context To free the struct: …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVCAMELLIA context.\n@file @brief Public header for libavutil CAMELLIA algorithm\nAllocate an AVCAST5 context To free the struct: …\nEncrypt or decrypt a buffer using a previously initialized …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVCAST5 context.\n@file @brief Public header for libavutil CAST5 algorithm …\nGet a human readable string describing a given channel.\nbprint variant of av_channel_description().\nThis is the inverse function of @ref av_channel_name().\nReturn the order if the layout is n-th order …\nGet the channel with the given index in a channel layout.\nGet a channel described by the given string.\nCheck whether a channel layout is valid, i.e. can possibly …\nCheck whether two channel layouts are semantically the …\nMake a copy of a channel layout. This differs from just …\nInitialize a custom channel layout with the specified …\nGet the default channel layout for a given number of …\nGet a human-readable string describing the channel layout …\nbprint variant of av_channel_layout_describe().\nInitialize a native channel layout from a bitmask …\nInitialize a channel layout from a given string …\nGet the index of a given channel in a channel layout. In …\nGet the index in a channel layout of a channel described …\nChange the AVChannelOrder of a channel layout.\nIterate over all standard channel layouts.\nFind out what channels from a given set are present in a …\nFree any allocated data in the channel layout and reset …\nGet a human readable string in an abbreviated form …\nbprint variant of av_channel_name().\nConverts AVChromaLocation to swscale x/y chroma position.\n@return the AVChromaLocation value for name or an AVError …\n@return the name for provided chroma location or NULL if …\nConverts swscale x/y chroma position to AVChromaLocation.\nA class for logging. Set by av_hwdevice_ctx_alloc().\nA class for logging.\ninformation on struct for av_log\nA class for private options.\nA class for @ref avoptions. Set on stream creation.\nA class for @ref avoptions. Set by …\nA class for logging and @ref avoptions. Set by …\n&lt; needed for av_log() and filters common options\nGet the AVCodecID for the given codec tag tag. If no codec …\nGet the codec tag for the given codec id id. If no codec …\nGet the codec tag for the given codec id.\n@return a non-zero number if codec is a decoder, zero …\n@return a non-zero number if codec is an encoder, zero …\nIterate over all registered codecs.\n@return the AVColorPrimaries value for name or an AVError …\n@return the name for provided color primaries or NULL if …\n@return the AVColorRange value for name or an AVError if …\n@return the name for provided color range or NULL if …\n@return the AVColorSpace value for name or an AVError if …\n@return the name for provided color space or NULL if …\n@return the AVColorTransferCharacteristic value for name …\n@return the name for provided color transfer or NULL if …\nCompare the remainders of two integer operands divided by …\nCompare two timestamps each in its own time base.\nAllocate a CPB properties structure and initialize its …\n@return the number of logical CPU cores present.\nOverrides cpu count detection and forces the specified …\nGet the maximum data alignment that may be required by …\nCalculate the CRC of a block. @param ctx initialized AVCRC …\nGet an initialized standard CRC table. @param crc_id ID of …\nInitialize a CRC table. @param ctx must be an array of …\nConvert a double precision floating point number to a …\nSet up DCT.\nReturn the context name\nIterate over all registered demuxers.\nCopy entries from one AVDictionary struct into another.\nGet number of entries in dictionary.\nFree all the memory allocated for an AVDictionary struct …\nGet a dictionary entry with matching key.\nGet dictionary entries as a string.\nIterate over a dictionary\nParse the key/value pairs list and add the parsed entries …\nSet the given entry in *pm, overwriting an existing entry.\nConvenience wrapper for av_dict_set() that converts the …\nThread safe dirname. @param path the string to parse, on …\nFlip the input matrix horizontally and/or vertically.\nExtract the rotation component of the transformation …\nInitialize a transformation matrix describing a pure …\n@return The AV_DISPOSITION_* flag corresponding to disp or …\n@param disposition a combination of AV_DISPOSITION_* values\nDivide one rational by another. @param b First rational …\nGet a frame’s AV_FRAME_DATA_DOWNMIX_INFO side data for …\nPrint detailed information about the input or output …\nGet a DV profile for the provided stream parameters.\nGet a DV profile for the provided stream parameters. The …\nGet a DV profile for the provided compressed frame.\nAdd an element of size <code>elem_size</code> to a dynamic array.\nAdd the pointer to an element to a dynamic array.\nAdd an element to a dynamic array.\nEscape string in src, and put the escaped string in an …\nTrack the presence of user provided functions and their …\nTrack the presence of variables and their number of …\nEvaluate a previously parsed expression.\nFree a parsed expression previously created with …\nParse an expression.\nParse and evaluate an expression. Note, this is …\nAllocate a buffer, reusing the given one if large enough.\nAllocate and clear a buffer, reusing the given one if …\nSame behaviour av_fast_malloc but the buffer has additional\nSame behaviour av_fast_padded_malloc except that buffer …\nReallocate the given buffer if it is not large enough, …\nDo a complex FFT with the parameters defined in …\nSet up a complex FFT. @param nbits           log2 of the …\nDo the permutation needed BEFORE calling ff_fft_calc(). …\nAllocate and initialize an AVFifo with a given element …\nSet the maximum size (in elements) to which the FIFO can …\n@return number of elements available for reading from the …\n@return Number of elements that can be written into the …\nDiscard the specified amount of data from an AVFifo. …\n@return Element size for FIFO operations. This element …\nFree an AVFifo and reset pointer to NULL. @param f Pointer …\nEnlarge an AVFifo.\nRead data from a FIFO without modifying FIFO state.\nFeed data from a FIFO into a user-provided callback.\nRead data from a FIFO.\nFeed data from a FIFO into a user-provided callback.\nWrite data into a FIFO.\nWrite data from a user-provided callback into a FIFO.\nRead the file with name filename, and put its content in a …\nUnmap or free the buffer bufptr created by av_file_map().\nCheck whether filename actually is a numbered sequence …\nIterate over all registered filters.\nCompute what kind of losses will occur when converting …\nFind the “best” stream in the file. The best stream is …\nAttempt to find a specific tag in a URL.\nFind AVInputFormat based on the short name of the input …\nFind the value in a list of rationals nearest a given …\nFind the programs which belong to a given stream.\nReturns the method used to set ctx-&gt;duration.\nDisables cpu detection and forces the specified flags. -1 …\nCallback used by devices to communicate with application.\nThis function will cause global side data to be injected …\nFill the provided buffer with a string containing a FourCC …\nAllocate an AVFrame and set its fields to default values.  …\nCrop the given video AVFrame according to its …\nCreate a new frame that references the same data as src.\nCopy the frame data from src to dst.\nCopy only “metadata” fields from src to dst.\nFree the frame and any dynamically allocated objects in it,\nAllocate new buffer(s) for audio or video data.\nGet the buffer reference a given data plane is stored in.\n@return a pointer to the side data of a given type on …\nCheck if the frame data is writable.\nEnsure that the frame data is writable, avoiding data copy …\nMove everything contained in src to dst and reset src.\nAdd a new side data to a frame.\nAdd a new side data to a frame from an existing AVBufferRef\nSet up a new reference to the data described by the source …\nRemove and free all side data instances of the given type.\nEnsure the destination frame refers to the same data …\nAdd a new side data entry to an array from an existing …\nAdd a new side data entry to an array based on existing …\n@return side data descriptor corresponding to a given side …\nFree all side data entries and their contents, then zeroes …\nGet a side data entry of a specific type from an array.\n@return a string identifying the side data type\nAdd new side data entry to an array.\nRemove and free all side data instances of the given type …\nUnreference all the buffers referenced by frame and reset …\nFree a memory block which has been allocated with a …\nFree a memory block which has been allocated with a …\nCompute the greatest common divisor of two integer …\nReturn the best rational so that a and b are multiple of …\nReturn the planar&lt;-&gt;packed alternative form of the given …\nReturn audio frame duration.\nThis function is the same as …\nReturn the number of bits per pixel used by the pixel …\nReturn codec bits per sample.\nReturn number of bytes per sample.\nReturn the flags which specify extensions supported by the …\nReturn codec bits per sample. Only return non-zero if the …\nReturn in ‘buf’ the path with ‘%d’ replaced by a …\nGet the name of a color from the internal table of …\nReturn a string describing the media_type enum, NULL if …\nGet timing information for the data currently output. The …\nGet the packed alternative form of the given sample format.\nAllocate and read the payload of a packet and initialize …\nReturn the number of bits per pixel for the pixel format …\nReturn the PCM codec associated with a sample format. …\nReturn a single letter to describe the given picture type …\nReturn the pixel format corresponding to name.\nCompute what kind of losses will occur when converting …\nReturn the short name for a pixel format, NULL in case …\nPrint in buf the string corresponding to the pixel format …\nGet the planar alternative form of the given sample format.\nReturn a name for the specified profile, if available.\nGet a seed to use in conjunction with random functions. …\nReturn a sample format corresponding to name, or …\nReturn the name of sample_fmt, or NULL if sample_fmt is not\nGenerate a string corresponding to the sample format with …\nReturn the fractional representation of the internal time …\nUnescape the given string until a non escaped terminating …\nGet the current time in microseconds.\nGet the current time in microseconds since some …\nIndicates with a boolean result if the …\nIncrease packet size, correctly zeroing padding\nGuess the codec ID based upon muxer and filename.\nReturn the output format in the list of registered output …\nGuess the frame rate, based on both the container and …\nGuess the sample aspect ratio of a frame, based on both …\nAllocate a hash context for the algorithm specified by …\nFinalize a hash context and compute the actual hash value.\nFinalize a hash context and store the Base64 …\nFinalize a hash context and store the actual hash value in …\nFinalize a hash context and store the hexadecimal …\nFree hash context and set hash context pointer to <code>NULL</code>.\nGet the name of the algorithm corresponding to the given …\nGet the size of the resulting hash value in bytes.\nInitialize or reset a hash context.\nGet the names of available hash algorithms.\nUpdate a hash context with additional data.\nSend a nice hexadecimal dump of a buffer to the specified …\nSend a nice hexadecimal dump of a buffer to the log.\nAllocate an AVHMAC context. @param type The hash function …\nHash an array of data with a key. @param ctx    The HMAC …\nFinish hashing and output the HMAC digest. @param ctx    …\nFree an AVHMAC context. @param ctx The context to free, …\nInitialize an AVHMAC context with an authentication key. …\nHash data with the HMAC. @param ctx  The HMAC context …\nAllocate an AVHWDeviceContext for a given hardware type.\nOpen a device of the specified type and create an …\nCreate a new device of the specified type from an existing …\nCreate a new device of the specified type from an existing …\nFinalize the device context before use. This function must …\nLook up an AVHWDeviceType by name.\nGet the constraints on HW frames given a device and the …\nGet the string name of an AVHWDeviceType.\nAllocate a HW-specific configuration structure for a given …\nIterate over supported device types.\nFree an AVHWFrameConstraints structure.\nAllocate an AVHWFramesContext tied to a given device …\nCreate and initialise an AVHWFramesContext as a mapping of …\nFinalize the context before use. This function must be …\nAllocate a new frame attached to the given …\nMap a hardware frame.\nCopy data to or from a hw surface. At least one of dst/src …\nGet a list of possible source or target formats usable in …\nAllocate an image with size w and h and pixel format …\nCheck if the given sample aspect ratio of an image is …\nCheck if the given dimension of an image is valid, meaning …\nCheck if the given dimension of an image is valid, meaning …\nCopy image in src_data to dst_data.\nCopy image plane from src to dst. That is, copy “height…\nCopy image data located in uncacheable (e.g. GPU mapped) …\nCopy image data from an image into a buffer.\nCopy image data located in uncacheable (e.g. GPU mapped) …\nSetup the data pointers and linesizes based on the …\nOverwrite the image data with black. This is suitable for …\nOverwrite the image data with a color. This is suitable …\nFill plane linesizes for an image with pixel format …\nCompute the max pixel step for each plane of an image with …\nFill plane sizes for an image with pixel format pix_fmt …\nFill plane data pointers for an image with pixel format …\nReturn the size in bytes of the amount of data required to …\nCompute the size of an image line with format pix_fmt and …\nGet the index for a specific timestamp.\nInitialize optional fields of a packet with default values.\nAudio input devices iterator.\nVideo input devices iterator.\nCompute the length of an integer list.\nWrite a packet to an output media file ensuring correct …\nWrite an uncoded frame to an output media file.\nSeed the state of the ALFG using binary data.\nSend the specified message to the log if the level is less …\nDefault logging callback\nFormat a line of log the same way as the default callback. …\nFormat a line of log the same way as the default callback. …\nGet the current log level\nSend the specified message to the log once with the …\nSet the logging callback\nSet the log level\n@brief Decodes LZO 1x compressed data. @param out output …\nAllocate a memory block with alignment suitable for all …\nAllocate a memory block for an array with av_malloc().\nAllocate a memory block with alignment suitable for all …\nReturn a positive value if the given filename has one of …\nCheck if a name is in a list. @returns 0 if not found, or …\nMatch instances of a name in a comma-separated list of …\nSet the maximum size that may be allocated in one block.\nAllocate an AVMD5 context.\nFinish hashing and output digest value.\nInitialize MD5 hashing.\n@defgroup lavu_md5 MD5 @ingroup lavu_hash MD5 hash …\nHash an array of data.\nUpdate hash value.\n@deprecated use av_tx_init from libavutil/tx.h with a type …\nOverlapping memcpy() implementation.\nDuplicate a buffer with av_malloc().\nMultiply two rationals. @param b First rational @param c …\nAllocate an AVMurMur3 hash context.\nFinish hashing and output digest value.\nInitialize or reinitialize an AVMurMur3 hash context.\nInitialize or reinitialize an AVMurMur3 hash context with …\nUpdate hash context with new data.\nIterate over all registered muxers.\nFind which of the two rationals is closer to another …\nAllocate the payload of a packet and initialize its fields …\nIterate over potential AVOptions-enabled children of …\nIterate over AVOptions-enabled children of obj.\nCopy options from src object into dest object.\n@defgroup opt_eval_funcs Evaluating option strings @{ This …\nLook for an option in an object. Consider only options …\nLook for an option in an object. Consider only options …\nCheck whether a particular flag is set in a flags field.\nFree all allocated objects in obj.\nFree an AVOptionRanges struct and set it to NULL.\n@defgroup opt_get_funcs Option getting functions @{ Those …\nFor an array-type option, retrieve the values of one or …\nFor an array-type option, get the number of elements in …\n@param[out] layout The returned layout is a copy of the …\n@param[out] out_val The returned dictionary is a copy of …\nExtract a key-value pair from the beginning of a string.\nCheck if given option is set to its default value.\nCheck if given option is set to its default value.\nIterate over all AVOptions belonging to obj.\nGets a pointer to the requested field in a struct. This …\nGet a list of allowed ranges for the given option.\nGet a default list of allowed ranges for the given option.\nSerialize object’s options.\n@defgroup opt_set_funcs Option setting functions @{ Those …\nAdd, replace, or remove elements for an array option. …\n@note Any old chlayout present is discarded and replaced …\nSet the values of all AVOption fields to their default …\nSet the values of all AVOption fields to their default …\nSet all the options from a given dictionary on an object.\nSet all the options from a given dictionary on an object.\n@note Any old dictionary present is discarded and replaced …\nParse the key-value pairs list in opts. For each key=value …\nShow the obj options.\nAudio output devices iterator.\nVideo output devices iterator.\nWrap an existing array as a packet side data.\nAllocate an AVPacket and set its fields to default values. …\nCreate a new packet that references the same data as src.\nCopy only “properties” fields from src to dst.\nFree the packet, if the packet is reference counted, it …\nConvenience function to free all the side data stored. All …\nInitialize a reference-counted packet from av_malloc()ed …\nGet side information from packet.\nEnsure the data described by a given packet is reference …\nCreate a writable reference for the data described by a …\nMove every field in src to dst and reset src.\nAllocate new information of a packet.\nPack a dictionary for use in side_data.\nSetup a new reference to the data described by a given …\nConvert valid timing fields (timestamps / durations) in a …\nShrink the already allocated side data buffer\nWrap existing data as packet side data.\nConvenience function to free all the side data stored in …\nGet side information from a side data array.\nAllocate a new packet side data.\nRemove side data of the given type from a side data array.\nUnpack a dictionary from side_data.\nWipe the packet.\nPut the RGBA values that correspond to color_string in …\nParse CPU caps from a string and update the given AV_CPU_* …\nParse str and store the parsed ratio in q.\nParse timestr and return in *time a corresponding number of\nParse str and store the detected values in *rate.\nParse str and put in width_ptr and height_ptr the detected …\nIterate over all registered codec parsers.\nParse a packet.\n@return number of planes in pix_fmt, a negative AVERROR if …\n@return a pixel format descriptor for provided pixel …\n@return an AVPixelFormat id described by desc, or …\nIterate over all pixel format descriptors known to …\nUtility function to access log2_chroma_w log2_chroma_h from\nUtility function to swap the endianness of a pixel format.\nSend a nice dump of a packet to the specified file stream.\nSend a nice dump of a packet to the log.\nLike av_probe_input_buffer2() but returns 0 on success\nProbe a bytestream to determine the input format. Each …\nGuess the file format.\nGuess the file format.\nGuess the file format.\nConvert an AVRational to a IEEE 32-bit <code>float</code> expressed in …\nGenerate cryptographically secure random data, i.e. …\nSet up a real FFT. @param nbits           log2 of the …\nReturn the next frame of a stream. This function returns …\nRead a line from an image, and write the values of the …\nPause a network-based stream (e.g. RTSP stream).\nStart playing a network-based stream (e.g. RTSP stream) at …\nAllocate, reallocate, or free a block of memory.\nAllocate, reallocate, or free an array.\nAllocate, reallocate, or free a block of memory.\nAllocate, reallocate, or free a block of memory through a …\nAllocate, reallocate an array through a pointer to a …\nReduce a fraction.\nRescale a 64-bit integer with rounding to nearest.\nRescale a timestamp while preserving known durations.\nRescale a 64-bit integer by 2 rational numbers.\nRescale a 64-bit integer by 2 rational numbers with …\nRescale a 64-bit integer with specified rounding.\nAllocate an AVRIPEMD context.\nFinish hashing and output digest value.\nInitialize RIPEMD hashing.\n@defgroup lavu_ripemd RIPEMD @ingroup lavu_hash RIPEMD …\nUpdate hash value.\nCheck if the sample format is planar.\nAllocate a samples buffer for nb_samples samples, and fill …\nAllocate a data pointers array, samples buffer for …\nCopy samples from src to dst.\nFill plane data pointers and linesize for samples with …\nGet the required buffer size for the given audio …\nFill an audio buffer with silence.\nGenerate an SDP for an RTP session.\nSeek to the keyframe at timestamp. ‘timestamp’ in ‘…\nParse the key/value pairs list in opts. For each key/value …\nAllocate an AVSHA512 context.\nFinish hashing and output digest value.\nInitialize SHA-2 512 hashing.\n@defgroup lavu_sha512 SHA-512 @ingroup lavu_hash SHA-512 …\nUpdate hash value.\nAllocate an AVSHA context.\nFinish hashing and output digest value.\nInitialize SHA-1 or SHA-2 hashing.\n@defgroup lavu_sha SHA @ingroup lavu_hash SHA-1 and …\nUpdate hash value.\nReduce packet size, correctly zeroing padding\nMultiply two <code>size_t</code> values checking for overflow.\nSimplified version of strptime\nSee libc sscanf manual for more information. …\nAllocate an AVStereo3D structure and set its fields to …\nAllocate an AVStereo3D structure and set its fields to …\nAllocate a complete AVFrameSideData and add it to the …\nGet the AVStereo3DType form a human-readable name.\nGet the AVStereo3DPrimaryEye form a human-readable name.\nProvide a human-readable name of a given stereo3d primary …\nProvide a human-readable name of a given stereo3d type.\nGet the AVStereo3DView form a human-readable name.\nProvide a human-readable name of a given stereo3d view.\nLocale-independent case-insensitive compare. @note This …\nDuplicate a string.\nWrap an existing array as stream side data.\nGet the AVClass for AVStream. It can be used in …\n@deprecated do not call this function\nGet side information from stream.\nGet the AVClass for AVStreamGroup. It can be used in …\nAllocate new information from stream.\nPut a description of the AVERROR code errnum in errbuf. In …\nLocale-independent strings replace. @note This means only …\nReturn non-zero if pfx is a prefix of str independent of …\nLocate the first case-independent occurrence in the string …\nAppend the string src to the string dst, but to a total …\nAppend output to a string, according to a format. Never …\nCopy the string src to dst, but no more than size - 1 …\nLocale-independent case-insensitive compare. @note This …\nDuplicate a substring of a string.\nLocate the first occurrence of the string needle in the …\nReturn non-zero if pfx is a prefix of str. If it is, *ptr …\nParse the string in numstr and return its value as a …\nSplit the string into several tokens which can be accessed …\nSubtract one rational from another. @param b First rational\nFlush the message queue\nAllocate a new message queue.\nFree a message queue.\nReturn the current number of messages in the queue.\nReceive a message from the queue.\nSend a message on the queue.\nSet the receiving error code.\nSet the sending error code.\nSet the optional free message callback function which will …\nAdjust frame number for NTSC drop frame time code.\nCheck if the timecode feature is available for the given …\nConvert sei info to SMPTE 12M binary representation.\nConvert frame number to SMPTE 12M binary representation.\nInit a timecode struct with the passed parameters.\nInit a timecode struct from the passed timecode components.\nParse timecode representation (hh:mm:ss[:;.]ff).\nGet the timecode string from the 25-bit timecode format …\nGet the timecode string from the SMPTE timecode format.\nGet the timecode string from the SMPTE timecode format.\nLoad timecode string in buf.\nConvert the decomposed UTC time in tm to a time_t value.\nAllocate an AVTWOFISH context To free the struct: …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVTWOFISH context.\n@file @brief Public header for libavutil TWOFISH algorithm …\nSplit a URL string into components.\nSleep for a period of time.  Although the duration is …\nRead and decode a single UTF-8 code point (character) from …\nAppend a formatted string to a print buffer.\nReturn an informative version string. This usually is the …\nSend the specified message to the log if the level is less …\nGet the duration for a Vorbis packet.\nGet the duration for a Vorbis packet.\nFree the parser and everything associated with it.\nAllocate and initialize the Vorbis parser using headers in …\nWrite a packet to an output media file.\nWrite the values from src to the pixel format component c …\nWrite the stream trailer to an output media file and free …\nWrite an uncoded frame to an output media file.\nTest whether a muxer supports uncoded frame.\nEncode extradata length to a buffer. Used by xiph codecs.\nAllocate an AVXTEA context.\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVXTEA context.\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVXTEA context.\nModify width and height values so that they will result in …\nModify width and height values so that they will result in …\nAllocate an AVCodecContext and set its fields to default …\nClose a given AVCodecContext and free all the data …\nReturn the libavcodec build-time configuration.\nDecode a subtitle message. Return a negative value on …\nThe default callback for AVCodecContext.get_buffer2(). It …\nThe default callback for …\n@return descriptor for given codec ID or NULL if no …\n@return codec descriptor with the given name or NULL if no …\nIterate over all codec descriptors known to libavcodec.\n@addtogroup lavc_encoding @{\nFill AVFrame audio data and linesize pointers.\nFind the best pixel format to convert to given a certain …\nFind a registered decoder with a matching codec ID.\nFind a registered decoder with the specified name.\nFind a registered encoder with a matching codec ID.\nFind a registered encoder with the specified name.\nReset the internal codec state / flush internal buffers. …\nFree the codec context and everything associated with it …\nGet the AVClass for AVCodecContext. It can be used in …\nRetrieve supported hardware configurations for a codec.\nCreate and return a AVHWFramesContext with values adequate …\nGet the name of a codec. @return  a static string …\nGet the AVClass for AVSubtitleRect. It can be used in …\nRetrieve a list of all supported values for a given …\nGet the type of the given codec.\n@return a positive value if s is open (i.e. …\nReturn the libavcodec license.\nInitialize the AVCodecContext to use the given AVCodec. …\nAllocate a new AVCodecParameters and set its fields to …\nCopy the contents of src to dst. Any allocated fields in …\nFree an AVCodecParameters instance and everything …\nFill the parameters struct based on the values from the …\nFill the codec context based on the values from the …\nReturn a value representing the fourCC code associated to …\nReturn a name for the specified profile, if available.\nReturn decoded output data from a decoder or encoder (when …\nRead encoded data from the encoder.\nSupply a raw video or audio frame to the encoder. Use …\nSupply raw packet data as input to a decoder.\n@}\nReturn the LIBAVCODEC_VERSION_INT constant.\nSend control message from application to device.\nReturn the libavdevice build-time configuration.\nSend control message from device to application.\nConvenient function to free result of …\nReturn the libavdevice license.\nList devices.\nList devices.\nInitialize libavdevice and register all the input and …\nReturn the LIBAVDEVICE_VERSION_INT constant.\nA function pointer passed to the @ref …\n@deprecated this function should never be called by users\nReturn the libavfilter build-time configuration.\nA function executing multiple jobs, possibly in parallel.\nGet the number of elements in an AVFilter’s inputs or …\nFree a filter context. This will also remove the filter …\nGet a filter definition matching the given name.\n@return AVClass for AVFilterContext.\nAllocate a filter graph.\nCreate a new filter instance in a filter graph.\nCheck validity and configure all the links and formats in …\nCreate and add a filter instance into an existing graph. …\nDump a graph into a human-readable string representation.\nFree a graph, destroy its links, and set *graph to NULL. …\nGet a filter instance identified by instance name from …\nAdd a graph described by a string to a graph.\nAdd a graph described by a string to a graph.\nAdd a graph described by a string to a graph.\nQueue a command for one or more filter instances.\nRequest a frame on the oldest sink link.\nApply all filter/link descriptions from a graph segment to …\nApply parsed options to filter instances in a graph …\nCreate filters specified in a graph segment.\nFree the provided AVFilterGraphSegment and everything …\nInitialize all filter instances in a graph segment.\nLink filters in a graph segment.\nParse a textual filtergraph description into an …\nSend a command to one or more filter instances.\nEnable or disable automatic format conversion inside the …\nInitialize a filter with the supplied dictionary of …\nInitialize a filter with the supplied parameters.\nAllocate a single AVFilterInOut entry. Must be freed with …\nFree the supplied list of AVFilterInOut and set *inout to …\nInsert a filter in the middle of an existing link.\nReturn the libavfilter license.\nLink two filters together.\n@deprecated this function should never be called by users\nGet the name of an AVFilterPad.\nGet the type of an AVFilterPad.\nMake the filter instance process a command. It is …\nReturn the LIBAVFILTER_VERSION_INT constant.\nAllocate an AVFormatContext. avformat_free_context() can …\nAllocate an AVFormatContext for an output format. …\nClose an opened input AVFormatContext. Free it and all its …\nReturn the libavformat build-time configuration.\nRead packets of a media file to get stream information. …\nDiscard all internally buffered data. This can be useful …\nFree an AVFormatContext and all its streams. @param s …\nGet the AVClass for AVFormatContext. It can be used in …\n@return the table mapping MOV FourCCs for audio to …\n@return the table mapping MOV FourCCs for video to …\n@return the table mapping RIFF FourCCs for audio to …\n@defgroup riff_fourcc RIFF FourCCs @{ Get the tables …\nGet the index entry count for the given AVStream.\nGet the AVIndexEntry corresponding to the given index.\nGet the AVIndexEntry corresponding to the given timestamp.\nAllocate the stream private data and initialize the codec, …\nReturn the libavformat license.\nCheck if the stream st contained in s is matched by the …\nUndo the initialization done by avformat_network_init. …\nDo global initialization of network libraries. This is …\nAdd a new stream to a media file.\nOpen an input stream and read the header. The codecs are …\nTest if the given container can store a codec.\nSeek to timestamp ts. Seeking will be done so that the …\nAdd an already allocated stream to a stream group.\nAdd a new empty stream group to a media file.\n@return a string identifying the stream group type, or …\n@deprecated do not call this function\nReturn the LIBAVFORMAT_VERSION_INT constant.\nAllocate the stream private data and write the stream …\nAverage bitrate of the stream, in bits per second. Zero if …\nAverage framerate\nAccept and allocate a client context on a server context. …\nAllocate and initialize an AVIOContext for buffered I/O. …\nReturn AVIO_FLAG_* access flags corresponding to the …\nClose the resource accessed by the AVIOContext s and free …\nClose directory.\nReturn the written size and a pointer to the buffer. The …\nClose the resource accessed by the AVIOContext *s, free it …\nFree the supplied IO context and everything associated …\nIterate through names of available protocols.\nSimilar to feof() but also returns nonzero on read errors. …\nReturn the name of the protocol that will handle the …\navio flags, used to force AVIO_FLAG_DIRECT.\nForce flushing of buffered data.\nFree entry allocated by avio_read_dir().\nReturn the written size and a pointer to the buffer. The …\nRead a string from pb into buf. The reading will terminate …\nRead a UTF-16 string from pb and convert it to UTF-8. The …\nPerform one step of the protocol handshake to accept a new …\nCreate and initialize a AVIOContext for accessing the …\nCreate and initialize a AVIOContext for accessing the …\nOpen directory for reading.\nOpen a write only memory stream.\nPause and resume playing - only meaningful if using a …\nWrite a NULL terminated array of strings to the context. …\nWrites a formatted string to the context. @return number …\nGet AVClass by names of available protocols.\nWrite a NULL-terminated string. @return number of bytes …\nConvert an UTF-8 string to UTF-16BE and write it. @param s …\nConvert an UTF-8 string to UTF-16LE and write it. @param s …\n@name Functions for reading from AVIOContext @{\nRead size bytes from AVIOContext into buf. @return number …\nGet next directory entry.\nRead size bytes from AVIOContext into buf. Unlike …\nRead contents of h into print buffer, up to max_size …\nfseek() equivalent for AVIOContext. @return new position …\nSeek to a given timestamp relative to some component …\nGet the filesize. @return filesize or AVERROR\nSkip given number of bytes forward @return new position or …\nWrites a formatted string to the context taking a va_list. …\nMark the written bytestream as a specific type.\nAvoid negative timestamps during muxing. Any value of the …\nFree all allocated data in the given subtitle struct.\nReturn the libavutil build-time configuration.\nReturn the libavutil license.\nReturn the LIBAVUTIL_VERSION_INT constant.\nqscale factor between IP and B-frames If &gt; 0 then the last …\nqscale offset between IP and B-frames\nThe pixel value per channel in RGBA format used if no …\nThe distance between the centres of the lenses of the …\nframe timestamp estimated using various heuristics, in …\nencoding: Set by user.decoding: unused\nThe average bitrate of the encoded data (in bits per …\nthe average bitrate\nTotal stream bitrate in bit/s, 0 if not available. Never …\nnumber of bits the bitstream is allowed to diverge from …\nThe number of bits per sample in the codedwords.\nbits per sample/pixel from the demuxer (needed for …\nThis is the number of valid bits in each output sample. If …\nBits per sample/pixel of internal libavcodec pixel/sample …\nAudio only. The number of bytes per coded audio frame, …\nnumber of bytes per packet if constant and known or 0 Used …\nAVBuffer references backing the data for this frame. All …\nA reference to the reference-counted buffer where the …\n&lt; Buffer must have AVPROBE_PADDING_SIZE of extra allocated …\n&lt; End of the data, may be less than buffer+buffer_size if …\n&lt; Current position in the buffer\nMaximum reached position before a backward seek in the …\n&lt; Size of buf except extra allocated bytes\n&lt; Start of the buffer.\nThe size of the buffer to which the ratecontrol is …\n&lt; Maximum buffer size\nRead-only statistic of bytes read for this AVIOContext.\nRead-only statistic of bytes written for this AVIOContext.\nCodec capabilities. see AV_CODEC_CAP_*\nHardware accelerated codec capabilities. see …\nCategory used for visualization (like color) This is only …\nAbsolute scale factor representing the nominal level of …\nAbsolute scale factor representing the nominal level of …\nChannel layout of the audio data.\nAudio only. The channel layout and number of channels.\nAudio channel layout.\n&lt; channel layout of current buffer (see …\nAudio only, the audio channel layout\nArray of supported channel layouts, terminated with a …\nA list of filter chain contained in this segment. Set in …\nLists of supported channel layouts, only for audio.\nIterate over the AVClasses corresponding to potential …\nReturn next AVOptions-enabled child or NULL\ncustom intra quantization matrix\nThis defines the location of chroma samples.\nThe name of the class; usually it is the same name as the …\nAVCodecDescriptor\nSpecific type of the encoded data (the codec used).\nAdditional information about the codec (corresponds to the …\nfourcc (LSB first, so “ABCD” -&gt; (‘D’&lt;&lt;24) + (‘C…\nList of supported codec_id-codec_tag pairs, ordered by “…\nGeneral type of the encoded data.\n‘,’ separated list of allowed decoders. If NULL then …\n‘,’ separated list of allowed decoders. If NULL then …\nCodec parameters associated with this stream. Allocated …\nBitstream width / height, may be different from …\nWidth of the canvas.\nAdditional data associated with the entire stream.\nAdditional data associated with the entire coded stream.\nBitstream width / height, may be different from …\nDimensions of the coded video.\nWidth of the canvas.\n&lt; pointer to the list of coefficients\nChromaticity coordinates of the source primaries.\nMPEG vs JPEG YUV range.\nVideo only. Additional colorspace characteristics.\nMPEG vs JPEG YUV range.\n&lt; agreed upon YUV color range\n&lt; AVColorRange\nVideo only, the YUV colorspace and range.\n&lt; AVColorSpace\nColor Transfer Characteristic.\nYUV colorspace type.\nYUV colorspace type.\n&lt; agreed upon YUV color space\nParameters that describe how pixels are packed. If the …\nValue’s component range. For string this represents the …\nValue’s component range. For string this represents the …\nencoding: Set by user.decoding: unused\nCallback used by devices to communicate with application.\nCorrect single timestamp overflows\n@anchor cropping @name Cropping Video frames only. The …\nFlags signalling stream properties. A combination of …\nPosition of the packet in file.\nAudio cutoff bandwidth (0 means “automatic”)\ndarkness masking (0-&gt; disabled)\nThe data buffer. It is considered writable if and only if …\npointer to the picture/channel planes. This might be …\ndata+linesize for the bitmap of this subtitle. Can be set …\nForced data codec. This allows forcing a specific decoder, …\nForced Data codec_id. Demuxing: Set by user.\nDCT algorithm, see FF_DCT_* below\ndebug\nFlags to enable debugging.\ndecode error flags of the frame, set to a combination of …\nArray containing static side data, such as HDR10 CLL / …\nNative access only.\n&lt; index of default device or -1 if no default\nCodec delay.\n&lt; Denominator\nNumber of bits in the component.\nA description of the filter. May be NULL.\nThe parent AVHWDeviceContext. This is simply a pointer to …\n&lt; human friendly name\n&lt; device name, format depends on device\nA reference to the parent AVHWDeviceContext. This …\nThe device type associated with the configuration.\n&lt; list of autodetected devices\nME diamond size &amp; shape\navio_read and avio_write should if possible be satisfied …\n&lt; Selects which packets can be discarded at will and do …\n&lt; selects which program to discard and which to feed to …\nThe percentage of damaged samples to discard a frame.\nStream disposition - a combination of AV_DISPOSITION_* …\nStream group disposition - a combination of AV_DISPOSITION_…\nIf non NULL, ‘draw_horiz_band’ is called by the …\n&lt; dest filter\nAbsolute destination position. Can be outside the frame …\nAbsolute destination position. Can be outside the frame …\n&lt; input pad on the dest filter\nDecompression timestamp in AVStream-&gt;time_base units; the …\nOffset of the current timestamp against last timestamp …\nSynchronization point for start of timestamp generation.\ndump format separator. can be “, “ or “\\n      “ …\ndump format separator. can be “, “ or “\\n      “ …\nDuration of the frame, in the same units as pts. 0 if …\nDuration of this packet in AVStream-&gt;time_base units, 0 if …\nDuration of the current frame. For audio, this is in units …\nDecoding: duration of the stream, in stream time base. If …\nDuration of the stream, in AV_TIME_BASE fractional …\nThe duration field can be estimated through various ways, …\nMaximum number of bytes read from input in order to …\n&lt; parsed expression (AVExpr*)\n&lt; enable expression string\n&lt; chapter start/end time in time_base units\n&lt; true if was unable to read due to error or eof\nError recognition; may misdetect some more or less valid …\nerror\n&lt; contains the error code or 0 if no error happened\nerror concealment flags\nError recognition; higher values will detect more errors …\nFlags indicating events happening on the stream, a …\nFlags indicating events happening on the file, a …\nThe codec may call this to execute several independent …\nThis callback may be set by the caller immediately after …\nThe codec may call this to execute several independent …\nBit set of AV_CODEC_EXPORT_DATA_* flags, which affects the …\nFor planar audio which requires more than …\npointers to the data planes/channels.\n&lt; comma-separated filename extensions\nIf extensions are defined, then no probe is done. You …\nVideo decoding only.  Sets the number of extra hardware …\nSets the number of extra hardware frames which the filter …\nExtra binary data needed for initializing the decoder, …\nsome codecs need / can use extradata like Huffman tables. …\nSize of the extradata content in bytes.\nDRM PRIME fd for the object.\nFile descriptor of DRM device.\nBuffer to print data progressively\nVideo only. The order of the fields in interlaced video.\nField order\n&lt; Unix file mode, -1 if unknown.\n&lt; the AVFilter of which this is an instance\nThe filter context.\nfilter context associated to this input/output\nName of the AVFilter to be used.\nFrame flags, a combination of @ref lavu_frame_flags\nA combination of AV_PKT_FLAG values\nAV_CODEC_FLAG_*.\nA combination of AV_OPT_FLAG_*.\ncan use flags: AVFMT_NOFILE, AVFMT_NEEDNUMBER, …\nCan use flags: AVFMT_NOFILE, AVFMT_NEEDNUMBER, …\nFlags modifying the (de)muxer behaviour. A combination of …\nA combination of AVFILTER_FLAG_*\nCombination of AV_PIX_FMT_FLAG_… flags.\nExtra flag information. Currently unused.\nAdditional information about the frame packing.\n&lt; flags such as drop frame, +24 hours support, …\nAV_CODEC_FLAG2_*\n&lt; Additional flags for avfilter internal use only.\nFlush the I/O context after each packet.\nformat of the frame, -1 if unknown or unset Values …\nThe pixel format identifying the underlying HW surface …\nvideo: the pixel format, the value corresponds to enum …\nThe format of the coded data, corresponds to enum …\n&lt; agreed upon media format\nvideo: the pixel format, value corresponds to enum …\nFormat of the layer (DRM_FORMAT_*).\nFormat modifier applied to the object (DRM_FORMAT_MOD_*).\nMaximum number of bytes read from input in order to …\n‘,’ separated list of allowed demuxers. If NULL then …\nList of supported formats (pixel or sample).\nThis field determines the state of the formats union. It …\n&lt; frame per second; must be consistent with the rate field\nThe number of frames used for determining the framerate in …\nFrame counter, set by libavcodec.\nVideo only, the frame rate of the input video. This field …\nAudio only. Audio frame size, if known. Required by some …\nNumber of samples per channel in an audio frame.\nVideo only. Number of frames per second, for streams with …\ndecoding: For codecs that store a framerate value in the …\nThis field may be set by the caller before calling …\nThis field may be set by the caller before calling …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThis callback is called at the beginning of each frame to …\nCallback to return the category. available since version …\nThis callback is called at the beginning of each packet to …\nCallback to negotiate the pixel format. Decoding only, may …\nGlobal quality for codecs which cannot change it per frame.\nthe number of pictures in a group of pictures, or 0 for …\n&lt; filtergraph this filter belongs to\nThe filtergraph this segment is associated with. Set by …\n&lt; Group ID of owner, -1 if unknown.\n&lt; height           of pict, undefined when pict is not set\n&lt; agreed upon image height\nWidth and height of the block.\nSize of the frame reordering buffer in the decoder. For …\n@name Video dimensions Video frames only. The coded …\nThe allocated dimensions of the frames in this pool.\npicture width / height.\nHeight of the final image for presentation.\nHeight of the final image for presentation.\n&lt; height\nVideo only, the display dimensions of the input frames.\nshort English help text @todo What about other languages?\nOffset in pixels from the left edge of the canvas where …\nRelative shift of the left and right images, which changes …\nHorizontal field of view, in degrees. Zero if unset.\nOffset in pixels from the left edge of the canvas where …\nA reference to the AVHWDeviceContext describing the device …\nFor filters which will create hardware frames, sets the …\nFor hwaccel-format frames, this should be a reference to …\nA reference to the AVHWFramesContext describing the input …\nVideo with a hwaccel pixel format only. This should be a …\nHardware accelerator in use\nLegacy hardware accelerator context.\nBit set of AV_HWACCEL_FLAG_* flags, which affect hardware …\nThe format-specific data, allocated and freed by libavutil …\nThe format-specific data, allocated and freed …\nqscale factor between P- and I-frames If &gt; 0 then the last …\nqscale offset between P and I-frames\nid\nCodec implemented by the hardware accelerator.\nFormat-specific stream ID. decoding: set by libavformat …\nGroup type-specific group ID.\n&lt; unique ID to identify the chapter\nIDCT algorithm, see FF_IDCT_* below.\nIndex of the stream in the group this tile references.\nThe input container format.\nIf set, don’t call write_data_type separately for …\ninterlaced DCT comparison function\nLists of supported formats / etc. supported by the input …\n&lt; stream index in AVFormatContext\nGroup index in AVFormatContext.\nFilter initialization function.\nAudio only. The amount of padding (in samples) inserted by …\nAudio only. The number of “priming” samples (padding) …\nInitial size of the frame pool. If a device type does not …\n&lt; array of input pads\nList of static inputs.\n&lt; array of pointers to input links\nName to be used for this filter instance.\ncustom inter quantization matrix Must be allocated with …\nThe content of the picture is interlaced.\nPrivate context used for internal data.\nCustom interrupt callbacks for the I/O layer.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nprecision of the intra DC coefficient - 8\ncustom intra quantization matrix Must be allocated with …\nA callback for closing the streams opened with …\nA callback for opening new IO streams.\nIO repositioned flag. This is set by avformat when the …\n&lt; the enabled state from the last expression evaluation\nRange flag. If set to 1 the struct encodes a range, if set …\nA pointer to a function which returns the name of a context\n1 -&gt; keyframe, 0-&gt; not\nSet by parser to 1 for key frames and 0 for non-key frames.\nminimum GOP size\nAn av_malloc()’ed string containing the pad label.\nPrevious frame byte position.\namount of previous MV predictors (2a+1 x 2a+1 square)\nArray of layers in the frame.\nIndex of the LCEVC data stream in AVStreamGroup.\n&lt; length so far\n&lt; length so far\n&lt; number of coefficients in the vector\nEncoding level descriptor.\nAbsolute scale factor representing the level at which the …\nFor video, a positive or negative value, which is …\nAmount to shift the luma height right to find the chroma …\nAmount to shift the luma width right to find the chroma …\nOffset in the structure where log_level_offset is stored. …\nDescriptive name for the codec, meant to be more human …\nA more descriptive name for this codec. May be NULL.\nDescriptive name for the format, meant to be more …\nDescriptive name for the format, meant to be more …\nlow resolution decoding, 1-&gt; 1/2 size, 2-&gt;1/4 size\nluminance masking (0-&gt; disabled)\nThis member must be used when the channel order is …\nThis member must be used for AV_CHANNEL_ORDER_NATIVE, and …\n&lt; maximum valid value for the option\nMaximum duration (in AV_TIME_BASE units) of the data read …\nmaximum number of B-frames between non-B-frames Note: The …\nMaximum bitrate of the stream, in bits per second. Zero if …\nMax chunk time in microseconds. Note, not all formats …\nMax chunk size in bytes Note, not all formats support this …\nMaximum amount of memory in bytes to use for the index of …\nMaximum buffering duration for interleaving.\n&lt; maximum value for lowres supported by the decoder\nMaximum amount of memory in bytes to use for buffering …\nThe number of pixels per image to maximally accept.\nMaximum number of packets that can be probed\nmaximum quantizer difference between frames\nThe number of samples per frame to maximally accept.\nThe maximum number of streams.\nMaximum number of packets to read while waiting for the …\nThe maximum size of frames in this hw_frames_ctx. (INT_MAX …\nmacroblock comparison function (not supported yet)\nmacroblock decision mode\nmaximum MB Lagrange multiplier\nminimum MB Lagrange multiplier\nmotion estimation comparison function\nmotion estimation prepass comparison function\nmaximum motion estimation search range in subpel units If …\nsubpixel motion estimation comparison function\nsubpel ME quality\n&lt; array indicating what media types(s), if any, a device …\nmetadata.\nMetadata that applies to the whole group.\nMetadata that applies to the whole file.\nNumber of bytes to be written as padding in a metadata …\nBit set of AV_CODEC_HW_CONFIG_METHOD_* flags, describing …\n&lt; mime_type, when known.\nComma-separated list of mime types. It is used check for …\nMIME type(s) associated with the codec. May be NULL; if …\n&lt; minimum valid value for the option\nMinimum bitrate of the stream, in bits per second. Zero if …\n&lt; Minimum distance between this and the previous keyframe, …\n&lt; Try to buffer at least this amount of data before …\nThe minimum size of frames in this hw_frames_ctx. (Zero if …\n&lt; Time of last modification in microseconds since unix …\nMotion vector src_x = dst_x + motion_x / motion_scale …\nMotion vector src_x = dst_x + motion_x / motion_scale …\nNote: Value depends upon the compare function used for …\nHuman-readable side data description.\n&lt; short name for the profile\nName of the codec implementation. The name is globally …\nName of the codec described by this descriptor. It is …\nName of the hardware accelerated codec. The name is …\n&lt; Filename\nA comma separated list of short names for the format. New …\nFilter name. Must be non-NULL and unique among filters.\n&lt; name of this filter instance\nunique name for this input/output in the list\nNumber of channels in this layout. Mandatory field.\nNumber of chapters in AVChapter array. When muxing, …\nAmount of entries in @ref coded_side_data.\n&lt; number of colors in pict, undefined when pict is not set\nNumber of componentes.\n&lt; The number of components each pixel has, (1-4)\n&lt; number of autodetected devices\nNumber of elements in extended_buf.\n&lt; number of frames in this stream if known or 0\nThe number of entries in the list of inputs.\n&lt; number of input pads\nNumber of layers in the frame.\n&lt; length of media_types array, 0 if device cannot provide …\nNumber of DRM objects making up this frame.\nThe number of entries in the list of outputs.\n&lt; number of output pads\nNumber of planes in the layer.\nNumber of ranges per component.\nnumber of audio samples (per channel) described by this …\nThe number of elements in the AVStream.side_data array.\nNumber of entries in side_data_prefer_packet.\nNumber of elements in AVFormatContext.stream_groups.\nNumber of elements in AVStreamGroup.streams.\nNumber of elements in AVFormatContext.streams.\nMax number of threads allowed in this filter instance. If &lt;…\nMaximum number of threads used by filters in this graph. …\nAmount of tiles in the grid.\nnext input/input in the list, NULL if this is the last\nnoise vs. sse weight for the nsse comparison function\n&lt; Numerator\nIndex of the object containing this plane in the objects …\nArray of objects making up the frame.\n&lt; byte offset from starting packet start\nNative access only.\nNumber of elements before the component of the first pixel.\nOffset within that object of this plane.\nThe output container format.\nFor some private data of the user.\nFrame owner’s private data.\nfor some private data of the user\nPrivate data of the user, can be used to carry app …\n&lt; A private pointer, passed to the read/write/seek/… …\nUser data. This is a place for some private data of the …\nOpaque user data. May be set by the caller to an arbitrary …\nFrame owner’s private data.\nAVBufferRef for free use by the API user. FFmpeg will …\na pointer to the first option specified in the class if …\nOptions to be apllied to the filter.\nChannel order used in this layout. This is a mandatory …\nLists of supported formats / etc. supported by the output …\n&lt; array of output pads\nPicture number incremented in presentation or output order.\nOutput timestamp offset, in microseconds. Muxing: set by …\nList of static outputs.\n&lt; array of pointers to output links\np block masking (0-&gt; disabled)\nindex of the filt_ctx pad to use for linking\nTell user application that palette has changed from …\nOffset in the structure where a pointer to the parent …\nI/O context.\nPicture type of the frame.\nIndicate whether a picture is coded as a frame, top field …\nPitch (linesize) of this plane.\nFor decoders, a hardware pixel format which that decoder …\nPixel format, see AV_PIX_FMT_xxx. May be set by the …\nSupported pixel format.\nEquivalent to { pix_fmt, AV_PIX_FMT_NONE } as pixels_list.\n&lt; @deprecated use avcodec_get_supported_config()\nA pointer to an array of admissible pixel formats delimited\nDTS copied from the AVPacket that triggered returning this …\nreordered pos from the last AVPacket that has been input …\nsize of the corresponding packet containing the compressed …\nTimebase in which pkt_dts/pts and AVPacket.dts/pts are …\nWhich of the 4 planes contains the component.\nArray of planes in this layer.\nA pool from which the frames are allocated by …\n&lt; byte position in stream, -1 if unknown\nByte position of currently parsed frame in stream.\n&lt; position in the file of the current buffer\nposition of the top left corner in 1/16 pel for up to 3 …\nME prepass diamond size &amp; shape\nType of downmix preferred by the mastering engineer.\nFilter pre-initialization function\nWhich eye is the primary eye when rendering in 2D.\n&lt; private data for use by the filter\n&lt; AVClass for the private context\n&lt; AVClass for the private context\n&lt; AVClass for the private context\nA class for the private data, used to declare filter …\nFormat private data. This is an AVOptions-enabled struct …\n&lt; size of private data to allocate for the filter\nAVBufferRef for internal use by a single libav* library. …\nformat probing score. The maximal score is …\nMaximum number of bytes read from input in order to …\nMake the filter instance process a command.\nCodec-specific bitstream restrictions that the stream …\nprofile\n&lt; array of recognized profiles, or NULL if unknown, array …\nIf non-NULL, an array of profiles recognized for this …\nProperties of the stream that gets decoded\nSide data property flags, a combination of AVSideDataProps …\nCodec properties, a combination of AV_CODEC_PROP_* flags.\n‘,’ separated list of disallowed protocols.\n‘,’ separated list of disallowed protocols.\n‘,’ separated list of allowed protocols.\n‘,’ separated list of allowed protocols.\nPresentation timestamp in time_base units (time when frame …\nPresentation timestamp in AVStream-&gt;time_base units; the …\n&lt; Same as packet pts, in AV_TIME_BASE\nPresentation delay of current frame in units of …\n&lt; behavior on wrap detection\nNumber of bits in timestamps. Used for wrapping control.\n&lt; reference dts for wrap detection\n&lt; amount of qscale smoothing over time (0.0-1.0)\n&lt; amount of qscale change between easy &amp; hard scenes …\nmaximum quantizer\nminimum quantizer\nQuantisation offset.\nquality (between 1 (good) and FF_LAMBDA_MAX (bad))\nQuery formats supported by the filter on its inputs and …\nSame as query_func(), except this function writes the …\nCallback to return the supported/allowed ranges. available …\nReal base framerate of the stream. This is the lowest …\nArray of option ranges.\n&lt; frame rate in rational form\ndecoder bitstream buffer size\nNumber of bits which should be loaded into the rc buffer …\nRatecontrol attempt to use, at maximum,  of what can be …\nmaximum bitrate\nminimum bitrate\nRatecontrol attempt to use, at least,  times the amount …\nratecontrol override, see RcOverride\nPause or resume playback for network streaming protocols - …\nSeek to a given timestamp in stream with the specified …\nReady status of the filter. A non-0 value means that the …\nnumber of reference frames\nNumber of fields in this frame which should be repeated, …\nThis field is used for proper frame duration computation …\ndesired sample format\nSample aspect ratio for the video frame, 0/1 if …\nVideo only. The aspect ratio (width / height) which a …\nsample aspect ratio (0 if unknown) That is the width of a …\nsample aspect ratio (0 if unknown)\n&lt; agreed upon sample aspect ratio\nVideo only, the sample (pixel) aspect ratio.\n&lt; sample format\nEquivalent to { sample_fmt, AV_SAMPLE_FMT_NONE } as …\n&lt; @deprecated use avcodec_get_supported_config()\nSample rate of the audio data.\nAudio only. The number of audio samples per second.\n&lt; samples per second\n&lt; samples per second\nAudio only, the audio sampling rate in samples per second.\nLists of supported sample rates, only for audio.\nAnalogous to pixels, but delimited by AV_SAMPLE_FMT_NONE …\n&lt; sws options to use for the auto-inserted scale filters\nA string containing a colon-separated list of key=value …\nForce seeking to any (also non key) frames.\nAudio only. Number of samples to skip after a …\nNumber of samples to skip after a discontinuity\nA combination of AVIO_SEEKABLE_ flags or 0 when the stream …\nMust be set to the size of this data structure (that is, …\nSeparator between array elements in string representations …\nNumber of least significant bits that must be shifted away …\nAdditional packet data that can be provided by the …\nAn array of side data that applies to the whole stream …\nDecoding only. May be set by the caller before …\nSize of data in bytes.\n&lt; File size in bytes, -1 if unknown.\n&lt; allocated memory\n&lt; allocated memory\nTotal size of the object.\nMaximum number of elements in the array, 0 when unlimited.\n&lt; maximum allocated memory\n&lt; maximum allocated memory\nMinimum number of elements in the array. When this field …\nSkip processing alpha if supported by codec. Note that if …\nNumber of macroblock rows at the bottom which are skipped.\nSkip duration calcuation in estimate_timings_from_pts.\nSkip decoding for selected frames.\nSkip IDCT/dequantization for selected frames.\nSkip initial bytes when opening stream\nSkip loop filtering for selected frames.\nNumber of macroblock rows at the top which are skipped.\nslice flags\nNumber of slices. Indicates number of picture …\nWhere the current macroblock comes from; negative value …\nspatial complexity masking (0-&gt; disabled)\n&lt; source filter\nAbsolute source position. Can be outside the frame area.\nAbsolute source position. Can be outside the frame area.\n&lt; output pad on the source filter\n&lt; chapter start/end time in time_base units\n&lt; timecode frame start (first base frame number)\nDecoding: pts of the first frame of the stream in …\nAll fields below this line are not part of the public API. …\nPosition of the first frame of the component, in …\nStart time of the stream in real world time, in …\npass2 encoding statistics input buffer Concatenated stuff …\npass1 encoding statistics output buffer\n&lt; Time of last status change in microseconds since unix …\nNumber of elements between 2 horizontally consecutive …\n&lt; string so far\n&lt; string so far\nA list of all stream groups in the file. New groups are …\nA list of streams in the group. New entries are created …\nA list of all streams in the file. New streams are created …\nstrictly follow the standard (MPEG-4, …).\nAllow non-standard and experimental extension @see …\nCharacter encoding of the input subtitles file.\nSubtitles character encoding mode. Formats or codecs might …\n&lt; default subtitle codec\nForced subtitle codec. This allows forcing a specific …\nForced subtitle codec_id. Demuxing: Set by user.\nHeader containing style information for text subtitles. …\n&lt; @deprecated use avcodec_get_supported_config()\n&lt; @deprecated use avcodec_get_supported_config()\nAbsolute scale factor representing the nominal level of …\nAbsolute scale factor representing the nominal level of …\nThe pixel format identifying the actual data layout of the …\nNominal unaccelerated pixel format, see AV_PIX_FMT_xxx.\nAllocate SwrContext.\nAllocate SwrContext if needed and set/reset common …\nGenerate a channel mixing matrix.\nCloses the context so that swr_is_initialized() returns 0.\nConfigure or reconfigure the SwrContext using the …\nConvert audio.\nConvert the samples in the input AVFrame and write them to …\nDrops the specified number of output samples.\nFree the given SwrContext and set the pointer to NULL.\nGet the AVClass for SwrContext. It can be used in …\nGets the delay the next input sample will experience …\nFind an upper bound on the number of samples that the next …\nInitialize context after user parameters have been set. …\nInjects the specified number of silence samples.\nCheck whether an swr context has been initialized or not.\nConvert the next timestamp from input to output timestamps …\nSet a customized input channel mapping.\nActivate resampling compensation (“soft” …\nSet a customized remix matrix.\nReturn the swr build-time configuration.\nReturn the swr license.\nReturn the @ref LIBSWRESAMPLE_VERSION_INT constant.\nAllocate and return an uninitialized vector with length …\nAllocate an empty SwsContext. This must be filled and …\nConvert an 8-bit paletted frame into a frame with a color …\nConvert an 8-bit paletted frame into a frame with a color …\nFinish the scaling process for a pair of …\nInitialize the scaling process for a given pair of …\nFree the swscaler context swsContext. If swsContext is …\nCheck if context can be reused, otherwise reallocate a new …\nReturn a pointer to yuv&lt;-&gt;rgb coefficients for the given …\n@return A negative error code on error, non negative …\nAllocate and return an SwsContext. You need it to perform …\nReturn a normalized Gaussian curve used to filter stuff …\nGet the AVClass for swsContext. It can be used in …\nInitialize the swscaler context sws_context.\n@param[in]  pix_fmt the pixel format @return a positive …\nReturn a positive value if pix_fmt is a supported input …\nReturn a positive value if pix_fmt is a supported output …\nScale all the coefficients of a so that their sum equals …\nRequest a horizontal slice of the output data to be …\nGet the alignment required for slices\nScale the image slice in srcSlice and put the resulting …\nScale all the coefficients of a by the scalar value.\nScale source data from src and write the output to dst.\nIndicate that a horizontal slice of input data is …\n@param c the scaling context @param dstRange flag …\nReturn the libswscale build-time configuration.\nReturn the libswscale license.\n@defgroup libsws libswscale Color conversion and scaling …\ntemporary complexity masking (0-&gt; disabled)\n&lt; 0 terminated plain UTF-8 text\nthread count is used to decide how many independent tasks …\nWhich multithreading methods to use. Use of …\nType of multithreading being allowed/used. A combination of\nType of multithreading allowed for filters in this graph. …\nFor some codecs, the time base is closer to the field rate …\nTime base for the timestamps in this frame. In the future, …\nTime base of the packet’s timestamps. In the future, …\nThis is the fundamental unit of time (in seconds) in terms …\nThis is the fundamental unit of time (in seconds) in terms …\n&lt; time base in which the start/end timestamps are specified\nDefine the time base used by the PTS of the frames/samples …\nThe timebase to be used for the timestamps on the input …\n&lt; Timestamp in AVStream.time_base units, preferably the …\nDistance in pixels from the top edge of the frame to the …\nIf the content is interlaced, is top field displayed first.\nTrack replay gain in microbels (divide by 100000 to get …\nPeak track amplitude, with 100000 representing full scale …\nAudio only. The amount of padding (in samples) appended by …\nAudio only. The amount of padding (in samples) appended by …\ntrellis RD quantization\nThis field identifies the underlying API used for hardware …\nType of codec implemented by the hardware accelerator.\n&lt; Type of the entry\nGroup type\n&lt; filter media type\nHow views are packed within the video.\nFilter uninitialization function.\nThe logical unit to which the option belongs. Non-constant …\ninput or output URL. Unlike the old filename field, this …\nforces the use of wallclock timestamps as pts/dts of …\n&lt; User ID of owner, -1 if unknown.\nArbitrary user data, to be used e.g. by the free() …\nArbitrary user data, to be used e.g. by the free() …\n&lt; Set to 1 when name is encoded with UTF-8, 0 otherwise. …\nA list of possible values for format in the hw_frames_ctx, …\nA list of possible values for sw_format in the …\nValue range. For string ranges this represents the min/max …\nValue range. For string ranges this represents the min/max …\n&lt; variable values for the enable expression\nThe delay between the time the packet this structure is …\nLIBAVUTIL_VERSION with which this structure was created. …\nOffset in pixels from the top edge of the canvas where the …\nOffset in pixels from the top edge of the canvas where the …\n&lt; default video codec\nForced video codec. This allows forcing a specific …\nForced video codec_id. Demuxing: Set by user.\nVideo only. Number of delayed frames.\nDetermines which views are packed.\n&lt; width            of pict, undefined when pict is not set\n&lt; agreed upon image width\nWidth and height of the block.\nA UTC timestamp, in microseconds, since Unix epoch (e.g, …\n@name Video dimensions Video frames only. The coded …\nThe allocated dimensions of the frames in this pool.\nwidth and height in 1/16 pel\nVideo only. The dimensions of the video frame in pixels.\npicture width / height.\nDimensions of the decoded video intended for presentation.\nWidth of the final image for presentation.\nWidth of the final stream for presentation.\n&lt; width\nVideo only, the display dimensions of the input frames.\nWork around bugs in encoders which sometimes cannot be …\nGroup name of the codec implementation. This is a short …\nA callback that is used instead of write_packet.\n&lt; true if open for writing\n&lt; top left corner  of pict, undefined when pict is not set\n&lt; x coordinate of top left corner\n&lt; top left corner  of pict, undefined when pict is not set\n&lt; y coordinate of top left corner")