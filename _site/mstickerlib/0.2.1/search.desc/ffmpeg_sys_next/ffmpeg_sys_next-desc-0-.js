searchState.loadedDescShard("ffmpeg_sys_next", 0, "@defgroup lavu_adler32 Adler-32 @ingroup lavu_hash …\nMessage types used by …\nBuffer to print data progressively\nThis structure contains the parameters describing the …\nThis structure describes the bitrate properties of an …\n@defgroup lavu_crc32 CRC @ingroup lavu_hash CRC (Cyclic …\nAVCodec.\nmain external API structure. New fields can be added to …\nThis struct describes the properties of a single codec …\nPrivate context used for internal data.\nThis struct describes the properties of an encoded stream.\n&lt; discard all\n&lt; discard all bidirectional frames\n&lt; discard useless packets like 0 size packets in avi\n&lt; discard nothing\n&lt; discard all non intra frames\n&lt; discard all frames except keyframes\n&lt; discard all non reference\nDRM device.\nDRM frame descriptor.\nDRM layer descriptor.\nDRM object descriptor.\nDRM plane descriptor.\nMessage types used by …\nStructure describes basic parameters of the device.\nList of devices.\n@ingroup lavc_decoding\nThis structure describes optional metadata relevant to a …\nPossible downmix types.\n&lt; all automatic conversions enabled\n&lt; all automatic conversions disabled\nCallback for writing or reading from a FIFO, passed to …\nFilter definition. This defines the pads a filter …\nA filterchain is a list of filter specifications.\nAn instance of a filter\nLists of formats / etc. supported by an end of a link.\nA parsed representation of a filtergraph segment.\nA linked-list of the inputs/outputs of the filter chain.\nA link between two filters. This contains pointers to the …\nParameters of a filter’s input or output pad.\nParameters describing a filter to be created in a …\nThe state of the following union is determined by …\n@defgroup lavu_hmac HMAC @ingroup lavu_crypto @{\n@defgroup lavc_hwaccel AVHWAccel\n@example ffhash.c This example is a simple command line …\nContext structure for the Lagged Fibonacci PRNG. The exact …\nThis structure stores compressed data. It is typically …\nThis structure stores auxiliary information for decoding, …\n@defgroup lavc_packet_side_data AVPacketSideData\nPan Scan area. This specifies the area which should be …\n@defgroup lavc_parsing Frame parsing @{\nDescriptor that unambiguously describes how the bits of a …\nThis structure supplies correlation between a packet …\nAVProfile.\nReplayGain information (see …\nStereo 3D type: this structure describes how two videos …\nList of possible primary eyes.\nList of possible 3D Types\nList of possible view types.\n@}\n@file @brief Public header for libavutil XTEA algorithm …\nGet volume/mute messages.\nGet volume/mute messages.\nMute control messages.\nDummy message.\nRequest pause/play.\nRequest pause/play.\nVolume control message.\nMute control messages.\nRequest pause/play.\nMute control messages.\nRepaint request message.\nWindow size change message.\n&lt; Not part of ABI\nKeep a reference to the frame. If the frame if …\nDo not check for format changes.\nImmediately push the frame to the output.\n&lt; AVChannelLayout, terminated by {0}\n&lt; AVColorRange, terminated by AVCOL_RANGE_UNSPECIFIED\n&lt; AVColorSpace, terminated by AVCOL_SPC_UNSPECIFIED\n&lt; AVRational, terminated by {0, 0}\n&lt; AVPixelFormat, terminated by AV_PIX_FMT_NONE\n&lt; AVSampleFormat, terminated by AV_SAMPLE_FMT_NONE\n&lt; int, terminated by 0\nThe codec supports this format by some ad-hoc method.\nThe codec supports this format via the hw_device_ctx …\nThe codec supports this format via the hw_frames_ctx …\nThe codec supports this format by some internal method.\nBuffer fullness status messages.\nBuffer readable/writable.\nBuffer fullness status messages.\nBuffer readable/writable.\nCreate window buffer message.\nDestroy window buffer message.\nDisplay window buffer message.\nMute state change message.\nDummy message.\nPrepare window buffer message.\nVolume level change message.\n&lt; Lt/Rt 2-channel downmix, Dolby Pro Logic II compatible.\n&lt; Lo/Ro 2-channel downmix (Stereo).\n&lt; Lt/Rt 2-channel downmix, Dolby Surround compatible.\n&lt; Number of downmix types. Not part of ABI.\n&lt; Not indicated.\nThe maximum number of layers/planes in a DRM frame.\n&lt; Use auto-selected escaping mode.\n&lt; Use backslash escaping.\n&lt; Use single-quote escaping.\n&lt; Use XML non-markup character data escaping.\n&lt; Bottom coded first, bottom displayed first\n&lt; Bottom coded first, top displayed first\n&lt; Top coded first, bottom displayed first\n&lt; Top coded_first, top displayed first\n&lt; coded as bottom field\n&lt; coded as frame\n&lt; coded as top field\n&lt; unknown\nATSC A53 Part 4 Closed Captions. This metadata should be …\nActive Format Description data consisting of a single byte …\nAmbient viewing environment metadata, as defined by H.274. …\nThis side data should be associated with an audio stream …\nContent light level (based on CTA-861.3). This metadata …\nThis side data corresponds to the AVCPBProperties struct.\nThis side data contains a 3x3 transformation matrix …\nDOVI configuration ref: …\nHDR10+ dynamic metadata associated with a video frame. The …\nThis side data contains encryption info for how to decrypt …\nThis side data is encryption initialization data. The …\nThis side data contains an integer value representing the …\nThe number of pixels to discard from the …\nAn AV_PKT_DATA_H263_MB_INFO side data packet contains a …\nIAMF Demixing Info Parameter Data associated with the …\nIAMF Mix Gain Parameter Data associated with the audio …\nIAMF Recon Gain Info Parameter Data associated with the …\nICC profile data consisting of an opaque octet buffer …\nAn AV_PKT_DATA_JP_DUALMONO side data packet indicates that …\nRaw LCEVC payload data, as a uint8_t array, with NAL …\nMastering display metadata (based on SMPTE-2086:2014). …\nData found in BlockAdditional element of matroska …\nA list of zero terminated key/value strings. There is no …\nMPEGTS stream ID as uint8_t, this is required to pass the …\nThe number of side data types. This is not part of the …\nThe AV_PKT_DATA_NEW_EXTRADATA is used to notify the codec …\nAn AV_PKT_DATA_PALETTE side data packet contains exactly …\nAn AV_PKT_DATA_PARAM_CHANGE side data packet is laid out …\nProducer Reference Time data corresponding to the …\nThis side data contains quality related information from …\nThis side data should be associated with an audio stream …\nTimecode which conforms to SMPTE ST 12-1:2014. The data is …\nRecommmends skipping the specified number of samples @code …\nThis side data should be associated with a video stream …\nThis side data should be associated with a video stream …\nA list of zero terminated key/value strings. There is no …\nSubtitle event position @code u32le x1 u32le y1 u32le x2 …\nThe optional first identifier line of a WebVTT cue.\nThe optional settings (rendering instructions) that …\nLeft eye.\nNeither eye.\nRight eye\nVideo is not stereoscopic (and metadata has to be there).\nViews are packed in a checkerboard-like structure per …\nViews are packed per column.\nViews are alternated temporally.\nViews are packed per line, as if interlaced.\nViews are next to each other.\nViews are next to each other, but when upscaling apply a …\nViews are on top of each other.\nVideo is stereoscopic but the packing is unspecified.\nFrame contains only the left view.\nFrame contains two packed views.\nFrame contains only the right view.\nContent is unspecified.\nPerform non-blocking operation. If this flag is set, send …\n&lt; timecode wraps after 24 hours\n&lt; negative time values are allowed\n&lt; timecode is drop frame\n@defgroup lavc_fft FFT functions @ingroup lavc_misc\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\nNo value.\n@ingroup lavc_encoding\nFormatted text, the ass field must be set by the decoder …\n&lt; A bitmap, pict will be set\nPlain text, the text field must be set by the decoder and …\n&lt; not part of API/ABI\n&lt; not part of API/ABI\n&lt; not part of API/ABI\n&lt; SoX Resampler\n&lt; SW Resampler\n&lt; Blackman Nuttall windowed sinc\n&lt; Cubic\n&lt; Kaiser windowed sinc\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nSome value of type <code>T</code>.\nDithering algorithms\nResampling Engines\nResampling Filter Types\n@defgroup lavfi_buffersrc Buffer source API @ingroup lavfi …\n@file API-specific header for AV_HWDEVICE_TYPE_DRM.\nFilter activation function.\nWhich multithreading methods are in use by the codec.\nSame as track_gain, but for the whole album.\nSame as track_peak, but for the whole album,\nAlternative comma-separated names.\nVideo decoding only. Certain video codecs support …\n&lt; swr options to use for the auto-inserted aresample …\n0 terminated ASS/SSA compatible event line. The …\nType of service that the audio stream conveys.\nCalculate the Adler32 checksum of a buffer.\nAllocate an AVAES context.\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVAES context.\n@defgroup lavu_aes AES @ingroup lavu_crypto @{\nAppend path component to the existing path. Path separator …\nPrint arguments following specified format into a large …\nAllocate an AVAudioFifo.\nDrain data from an AVAudioFifo.\nFree an AVAudioFifo.\nPeek data from an AVAudioFifo.\nPeek data from an AVAudioFifo.\nRead data from an AVAudioFifo.\nReallocate an AVAudioFifo.\nReset the AVAudioFifo buffer.\nGet the current number of samples in the AVAudioFifo …\nGet the current number of samples in the AVAudioFifo …\nWrite data to an AVAudioFifo.\nDecode a base64-encoded string.\nEncode data to base64 and null-terminate.\nThread safe basename. @param path the string to parse, on …\nAllocate an AVBlowfish context.\nEncrypt or decrypt a buffer using a previously initialized …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVBlowfish context.\nGet the next two numbers generated by a Box-Muller Gaussian\nAppend data to a print buffer.\nAppend char c n times to a print buffer.\nReset the string to “” but keep internal allocated …\nEscape the content in src and append it to dstbuf.\nFinalize a print buffer.\nAllocate bytes in the buffer for external use.\nInit a print buffer.\nInit a print buffer using a pre-existing buffer.\nAppend a formatted date and time to a print buffer.\nAppend a formatted string to a print buffer.\nGet a frame with filtered data from sink and put it in …\nGet a frame with filtered data from sink and put it in …\nSame as av_buffersink_get_frame(), but with the ability to …\n@defgroup lavfi_buffersink_accessors Buffer sink accessors …\nSet the frame size for an audio buffer sink.\nAdd a frame to the buffer source.\nAdd a frame to the buffer source.\nClose the buffer source after EOF.\nGet the number of failed requests.\nAllocate a new AVBufferSrcParameters instance. It should …\nInitialize the buffersrc or abuffersrc filter with the …\nAdd a frame to the buffer source.\nAllocate an AVCAMELLIA context To free the struct: …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVCAMELLIA context.\n@file @brief Public header for libavutil CAMELLIA algorithm\nAllocate an AVCAST5 context To free the struct: …\nEncrypt or decrypt a buffer using a previously initialized …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVCAST5 context.\n@file @brief Public header for libavutil CAST5 algorithm …\nConverts AVChromaLocation to swscale x/y chroma position.\n@return the AVChromaLocation value for name or an AVError …\n@return the name for provided chroma location or NULL if …\nConverts swscale x/y chroma position to AVChromaLocation.\ninformation on struct for av_log\n&lt; needed for av_log() and filters common options\n@return a non-zero number if codec is a decoder, zero …\n@return a non-zero number if codec is an encoder, zero …\nIterate over all registered codecs.\n@return the AVColorPrimaries value for name or an AVError …\n@return the name for provided color primaries or NULL if …\n@return the AVColorRange value for name or an AVError if …\n@return the name for provided color range or NULL if …\n@return the AVColorSpace value for name or an AVError if …\n@return the name for provided color space or NULL if …\n@return the AVColorTransferCharacteristic value for name …\n@return the name for provided color transfer or NULL if …\nAllocate a CPB properties structure and initialize its …\n@return the number of logical CPU cores present.\nOverrides cpu count detection and forces the specified …\nGet the maximum data alignment that may be required by …\nCalculate the CRC of a block. @param ctx initialized AVCRC …\nGet an initialized standard CRC table. @param crc_id ID of …\nInitialize a CRC table. @param ctx must be an array of …\nSet up DCT.\nThread safe dirname. @param path the string to parse, on …\nFlip the input matrix horizontally and/or vertically.\nExtract the rotation component of the transformation …\nInitialize a transformation matrix describing a pure …\nGet a frame’s AV_FRAME_DATA_DOWNMIX_INFO side data for …\nGet a DV profile for the provided stream parameters.\nGet a DV profile for the provided stream parameters. The …\nGet a DV profile for the provided compressed frame.\nEscape string in src, and put the escaped string in an …\nTrack the presence of user provided functions and their …\nTrack the presence of variables and their number of …\nEvaluate a previously parsed expression.\nFree a parsed expression previously created with …\nParse an expression.\nParse and evaluate an expression. Note, this is …\nSame behaviour av_fast_malloc but the buffer has additional\nSame behaviour av_fast_padded_malloc except that buffer …\nDo a complex FFT with the parameters defined in …\nSet up a complex FFT. @param nbits           log2 of the …\nDo the permutation needed BEFORE calling ff_fft_calc(). …\nAllocate and initialize an AVFifo with a given element …\nSet the maximum size (in elements) to which the FIFO can …\n@return number of elements available for reading from the …\n@return Number of elements that can be written into the …\nDiscard the specified amount of data from an AVFifo. …\n@return Element size for FIFO operations. This element …\nFree an AVFifo and reset pointer to NULL. @param f Pointer …\nEnlarge an AVFifo.\nRead data from a FIFO without modifying FIFO state.\nFeed data from a FIFO into a user-provided callback.\nRead data from a FIFO.\nFeed data from a FIFO into a user-provided callback.\nWrite data into a FIFO.\nWrite data from a user-provided callback into a FIFO.\nRead the file with name filename, and put its content in a …\nUnmap or free the buffer bufptr created by av_file_map().\nIterate over all registered filters.\nCompute what kind of losses will occur when converting …\nAttempt to find a specific tag in a URL.\nDisables cpu detection and forces the specified flags. -1 …\nReturn audio frame duration.\nThis function is the same as …\nReturn the number of bits per pixel used by the pixel …\nReturn the flags which specify extensions supported by the …\nGet the name of a color from the internal table of …\nReturn the number of bits per pixel for the pixel format …\nReturn the pixel format corresponding to name.\nCompute what kind of losses will occur when converting …\nReturn the short name for a pixel format, NULL in case …\nPrint in buf the string corresponding to the pixel format …\nReturn a name for the specified profile, if available.\nGet a seed to use in conjunction with random functions. …\nUnescape the given string until a non escaped terminating …\nGet the current time in microseconds.\nGet the current time in microseconds since some …\nIndicates with a boolean result if the …\nIncrease packet size, correctly zeroing padding\nAllocate a hash context for the algorithm specified by …\nFinalize a hash context and compute the actual hash value.\nFinalize a hash context and store the Base64 …\nFinalize a hash context and store the actual hash value in …\nFinalize a hash context and store the hexadecimal …\nFree hash context and set hash context pointer to <code>NULL</code>.\nGet the name of the algorithm corresponding to the given …\nGet the size of the resulting hash value in bytes.\nInitialize or reset a hash context.\nGet the names of available hash algorithms.\nUpdate a hash context with additional data.\nAllocate an AVHMAC context. @param type The hash function …\nHash an array of data with a key. @param ctx    The HMAC …\nFinish hashing and output the HMAC digest. @param ctx    …\nFree an AVHMAC context. @param ctx The context to free, …\nInitialize an AVHMAC context with an authentication key. …\nHash data with the HMAC. @param ctx  The HMAC context …\nAllocate an image with size w and h and pixel format …\nCheck if the given sample aspect ratio of an image is …\nCheck if the given dimension of an image is valid, meaning …\nCheck if the given dimension of an image is valid, meaning …\nCopy image in src_data to dst_data.\nCopy image plane from src to dst. That is, copy “height…\nCopy image data located in uncacheable (e.g. GPU mapped) …\nCopy image data from an image into a buffer.\nCopy image data located in uncacheable (e.g. GPU mapped) …\nSetup the data pointers and linesizes based on the …\nOverwrite the image data with black. This is suitable for …\nOverwrite the image data with a color. This is suitable …\nFill plane linesizes for an image with pixel format …\nCompute the max pixel step for each plane of an image with …\nFill plane sizes for an image with pixel format pix_fmt …\nFill plane data pointers for an image with pixel format …\nReturn the size in bytes of the amount of data required to …\nCompute the size of an image line with format pix_fmt and …\nInitialize optional fields of a packet with default values.\nAudio input devices iterator.\nVideo input devices iterator.\nSeed the state of the ALFG using binary data.\n@brief Decodes LZO 1x compressed data. @param out output …\nCheck if a name is in a list. @returns 0 if not found, or …\nMatch instances of a name in a comma-separated list of …\nAllocate an AVMD5 context.\nFinish hashing and output digest value.\nInitialize MD5 hashing.\n@defgroup lavu_md5 MD5 @ingroup lavu_hash MD5 hash …\nHash an array of data.\nUpdate hash value.\n@deprecated use av_tx_init from libavutil/tx.h with a type …\nAllocate an AVMurMur3 hash context.\nFinish hashing and output digest value.\nInitialize or reinitialize an AVMurMur3 hash context.\nInitialize or reinitialize an AVMurMur3 hash context with …\nUpdate hash context with new data.\nAllocate the payload of a packet and initialize its fields …\nAudio output devices iterator.\nVideo output devices iterator.\nWrap an existing array as a packet side data.\nAllocate an AVPacket and set its fields to default values. …\nCreate a new packet that references the same data as src.\nCopy only “properties” fields from src to dst.\nFree the packet, if the packet is reference counted, it …\nConvenience function to free all the side data stored. All …\nInitialize a reference-counted packet from av_malloc()ed …\nGet side information from packet.\nEnsure the data described by a given packet is reference …\nCreate a writable reference for the data described by a …\nMove every field in src to dst and reset src.\nAllocate new information of a packet.\nPack a dictionary for use in side_data.\nSetup a new reference to the data described by a given …\nConvert valid timing fields (timestamps / durations) in a …\nShrink the already allocated side data buffer\nWrap existing data as packet side data.\nConvenience function to free all the side data stored in …\nGet side information from a side data array.\nAllocate a new packet side data.\nRemove side data of the given type from a side data array.\nUnpack a dictionary from side_data.\nWipe the packet.\nPut the RGBA values that correspond to color_string in …\nParse CPU caps from a string and update the given AV_CPU_* …\nParse str and store the parsed ratio in q.\nParse timestr and return in *time a corresponding number of\nParse str and store the detected values in *rate.\nParse str and put in width_ptr and height_ptr the detected …\nIterate over all registered codec parsers.\nParse a packet.\n@return number of planes in pix_fmt, a negative AVERROR if …\n@return a pixel format descriptor for provided pixel …\n@return an AVPixelFormat id described by desc, or …\nIterate over all pixel format descriptors known to …\nUtility function to access log2_chroma_w log2_chroma_h from\nUtility function to swap the endianness of a pixel format.\nGenerate cryptographically secure random data, i.e. …\nSet up a real FFT. @param nbits           log2 of the …\nRead a line from an image, and write the values of the …\nAllocate an AVRIPEMD context.\nFinish hashing and output digest value.\nInitialize RIPEMD hashing.\n@defgroup lavu_ripemd RIPEMD @ingroup lavu_hash RIPEMD …\nUpdate hash value.\nAllocate an AVSHA512 context.\nFinish hashing and output digest value.\nInitialize SHA-2 512 hashing.\n@defgroup lavu_sha512 SHA-512 @ingroup lavu_hash SHA-512 …\nUpdate hash value.\nAllocate an AVSHA context.\nFinish hashing and output digest value.\nInitialize SHA-1 or SHA-2 hashing.\n@defgroup lavu_sha SHA @ingroup lavu_hash SHA-1 and …\nUpdate hash value.\nReduce packet size, correctly zeroing padding\nSimplified version of strptime\nSee libc sscanf manual for more information. …\nAllocate an AVStereo3D structure and set its fields to …\nAllocate an AVStereo3D structure and set its fields to …\nAllocate a complete AVFrameSideData and add it to the …\nGet the AVStereo3DType form a human-readable name.\nGet the AVStereo3DPrimaryEye form a human-readable name.\nProvide a human-readable name of a given stereo3d primary …\nProvide a human-readable name of a given stereo3d type.\nGet the AVStereo3DView form a human-readable name.\nProvide a human-readable name of a given stereo3d view.\nLocale-independent case-insensitive compare. @note This …\nLocale-independent strings replace. @note This means only …\nReturn non-zero if pfx is a prefix of str independent of …\nLocate the first case-independent occurrence in the string …\nAppend the string src to the string dst, but to a total …\nAppend output to a string, according to a format. Never …\nCopy the string src to dst, but no more than size - 1 …\nLocale-independent case-insensitive compare. @note This …\nLocate the first occurrence of the string needle in the …\nReturn non-zero if pfx is a prefix of str. If it is, *ptr …\nParse the string in numstr and return its value as a …\nSplit the string into several tokens which can be accessed …\nFlush the message queue\nAllocate a new message queue.\nFree a message queue.\nReturn the current number of messages in the queue.\nReceive a message from the queue.\nSend a message on the queue.\nSet the receiving error code.\nSet the sending error code.\nSet the optional free message callback function which will …\nAdjust frame number for NTSC drop frame time code.\nCheck if the timecode feature is available for the given …\nConvert sei info to SMPTE 12M binary representation.\nConvert frame number to SMPTE 12M binary representation.\nInit a timecode struct with the passed parameters.\nInit a timecode struct from the passed timecode components.\nParse timecode representation (hh:mm:ss[:;.]ff).\nGet the timecode string from the 25-bit timecode format …\nGet the timecode string from the SMPTE timecode format.\nGet the timecode string from the SMPTE timecode format.\nLoad timecode string in buf.\nConvert the decomposed UTC time in tm to a time_t value.\nAllocate an AVTWOFISH context To free the struct: …\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVTWOFISH context.\n@file @brief Public header for libavutil TWOFISH algorithm …\nSleep for a period of time.  Although the duration is …\nRead and decode a single UTF-8 code point (character) from …\nAppend a formatted string to a print buffer.\nGet the duration for a Vorbis packet.\nGet the duration for a Vorbis packet.\nFree the parser and everything associated with it.\nAllocate and initialize the Vorbis parser using headers in …\nWrite the values from src to the pixel format component c …\nEncode extradata length to a buffer. Used by xiph codecs.\nAllocate an AVXTEA context.\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVXTEA context.\nEncrypt or decrypt a buffer using a previously initialized …\nInitialize an AVXTEA context.\nModify width and height values so that they will result in …\nModify width and height values so that they will result in …\nAllocate an AVCodecContext and set its fields to default …\nClose a given AVCodecContext and free all the data …\nReturn the libavcodec build-time configuration.\nDecode a subtitle message. Return a negative value on …\nThe default callback for AVCodecContext.get_buffer2(). It …\nThe default callback for …\n@return descriptor for given codec ID or NULL if no …\n@return codec descriptor with the given name or NULL if no …\nIterate over all codec descriptors known to libavcodec.\n@addtogroup lavc_encoding @{\nFill AVFrame audio data and linesize pointers.\nFind the best pixel format to convert to given a certain …\nFind a registered decoder with a matching codec ID.\nFind a registered decoder with the specified name.\nFind a registered encoder with a matching codec ID.\nFind a registered encoder with the specified name.\nReset the internal codec state / flush internal buffers. …\nFree the codec context and everything associated with it …\nGet the AVClass for AVCodecContext. It can be used in …\nRetrieve supported hardware configurations for a codec.\nCreate and return a AVHWFramesContext with values adequate …\nGet the AVClass for AVSubtitleRect. It can be used in …\nRetrieve a list of all supported values for a given …\n@return a positive value if s is open (i.e. …\nReturn the libavcodec license.\nInitialize the AVCodecContext to use the given AVCodec. …\nAllocate a new AVCodecParameters and set its fields to …\nCopy the contents of src to dst. Any allocated fields in …\nFree an AVCodecParameters instance and everything …\nFill the parameters struct based on the values from the …\nFill the codec context based on the values from the …\nReturn a value representing the fourCC code associated to …\nReturn decoded output data from a decoder or encoder (when …\nRead encoded data from the encoder.\nSupply a raw video or audio frame to the encoder. Use …\nSupply raw packet data as input to a decoder.\n@}\nReturn the LIBAVCODEC_VERSION_INT constant.\nSend control message from application to device.\nReturn the libavdevice build-time configuration.\nSend control message from device to application.\nConvenient function to free result of …\nReturn the libavdevice license.\nList devices.\nList devices.\nInitialize libavdevice and register all the input and …\nReturn the LIBAVDEVICE_VERSION_INT constant.\nA function pointer passed to the @ref …\n@deprecated this function should never be called by users\nReturn the libavfilter build-time configuration.\nA function executing multiple jobs, possibly in parallel.\nGet the number of elements in an AVFilter’s inputs or …\nFree a filter context. This will also remove the filter …\nGet a filter definition matching the given name.\n@return AVClass for AVFilterContext.\nAllocate a filter graph.\nCreate a new filter instance in a filter graph.\nCheck validity and configure all the links and formats in …\nCreate and add a filter instance into an existing graph. …\nDump a graph into a human-readable string representation.\nFree a graph, destroy its links, and set *graph to NULL. …\nGet a filter instance identified by instance name from …\nAdd a graph described by a string to a graph.\nAdd a graph described by a string to a graph.\nAdd a graph described by a string to a graph.\nQueue a command for one or more filter instances.\nRequest a frame on the oldest sink link.\nApply all filter/link descriptions from a graph segment to …\nApply parsed options to filter instances in a graph …\nCreate filters specified in a graph segment.\nFree the provided AVFilterGraphSegment and everything …\nInitialize all filter instances in a graph segment.\nLink filters in a graph segment.\nParse a textual filtergraph description into an …\nSend a command to one or more filter instances.\nEnable or disable automatic format conversion inside the …\nInitialize a filter with the supplied dictionary of …\nInitialize a filter with the supplied parameters.\nAllocate a single AVFilterInOut entry. Must be freed with …\nFree the supplied list of AVFilterInOut and set *inout to …\nInsert a filter in the middle of an existing link.\nReturn the libavfilter license.\nLink two filters together.\n@deprecated this function should never be called by users\nGet the name of an AVFilterPad.\nGet the type of an AVFilterPad.\nMake the filter instance process a command. It is …\nReturn the LIBAVFILTER_VERSION_INT constant.\nAverage bitrate of the stream, in bits per second. Zero if …\nFree all allocated data in the given subtitle struct.\nqscale factor between IP and B-frames If &gt; 0 then the last …\nqscale offset between IP and B-frames\nThe distance between the centres of the lenses of the …\nencoding: Set by user.decoding: unused\nThe average bitrate of the encoded data (in bits per …\nthe average bitrate\nnumber of bits the bitstream is allowed to diverge from …\nThe number of bits per sample in the codedwords.\nbits per sample/pixel from the demuxer (needed for …\nThis is the number of valid bits in each output sample. If …\nBits per sample/pixel of internal libavcodec pixel/sample …\nAudio only. The number of bytes per coded audio frame, …\nnumber of bytes per packet if constant and known or 0 Used …\nA reference to the reference-counted buffer where the …\nThe size of the buffer to which the ratecontrol is …\nCodec capabilities. see AV_CODEC_CAP_*\nHardware accelerated codec capabilities. see …\nAbsolute scale factor representing the nominal level of …\nAbsolute scale factor representing the nominal level of …\nAudio only. The channel layout and number of channels.\nAudio channel layout.\n&lt; channel layout of current buffer (see …\nAudio only, the audio channel layout\nArray of supported channel layouts, terminated with a …\nA list of filter chain contained in this segment. Set in …\nLists of supported channel layouts, only for audio.\ncustom intra quantization matrix\nThis defines the location of chroma samples.\nAVCodecDescriptor\nSpecific type of the encoded data (the codec used).\nAdditional information about the codec (corresponds to the …\nfourcc (LSB first, so “ABCD” -&gt; (‘D’&lt;&lt;24) + (‘C…\nGeneral type of the encoded data.\n‘,’ separated list of allowed decoders. If NULL then …\nBitstream width / height, may be different from …\nAdditional data associated with the entire stream.\nAdditional data associated with the entire coded stream.\nBitstream width / height, may be different from …\nDimensions of the coded video.\n&lt; pointer to the list of coefficients\nChromaticity coordinates of the source primaries.\nVideo only. Additional colorspace characteristics.\nMPEG vs JPEG YUV range.\n&lt; agreed upon YUV color range\n&lt; AVColorRange\nVideo only, the YUV colorspace and range.\n&lt; AVColorSpace\nColor Transfer Characteristic.\nYUV colorspace type.\n&lt; agreed upon YUV color space\nParameters that describe how pixels are packed. If the …\nencoding: Set by user.decoding: unused\nPosition of the packet in file.\nAudio cutoff bandwidth (0 means “automatic”)\ndarkness masking (0-&gt; disabled)\ndata+linesize for the bitmap of this subtitle. Can be set …\nDCT algorithm, see FF_DCT_* below\ndebug\nArray containing static side data, such as HDR10 CLL / …\n&lt; index of default device or -1 if no default\nCodec delay.\nNumber of bits in the component.\nA description of the filter. May be NULL.\n&lt; human friendly name\n&lt; device name, format depends on device\nThe device type associated with the configuration.\n&lt; list of autodetected devices\nME diamond size &amp; shape\nThe percentage of damaged samples to discard a frame.\nIf non NULL, ‘draw_horiz_band’ is called by the …\n&lt; dest filter\nAbsolute destination position. Can be outside the frame …\nAbsolute destination position. Can be outside the frame …\n&lt; input pad on the dest filter\nDecompression timestamp in AVStream-&gt;time_base units; the …\nOffset of the current timestamp against last timestamp …\nSynchronization point for start of timestamp generation.\ndump format separator. can be “, “ or “\\n      “ …\nDuration of this packet in AVStream-&gt;time_base units, 0 if …\nDuration of the current frame. For audio, this is in units …\n&lt; parsed expression (AVExpr*)\n&lt; enable expression string\nError recognition; may misdetect some more or less valid …\nerror\nerror concealment flags\nThe codec may call this to execute several independent …\nThis callback may be set by the caller immediately after …\nThe codec may call this to execute several independent …\nBit set of AV_CODEC_EXPORT_DATA_* flags, which affects the …\nVideo decoding only.  Sets the number of extra hardware …\nSets the number of extra hardware frames which the filter …\nExtra binary data needed for initializing the decoder, …\nsome codecs need / can use extradata like Huffman tables. …\nSize of the extradata content in bytes.\nDRM PRIME fd for the object.\nFile descriptor of DRM device.\nBuffer to print data progressively\nVideo only. The order of the fields in interlaced video.\nField order\n&lt; the AVFilter of which this is an instance\nThe filter context.\nfilter context associated to this input/output\nName of the AVFilter to be used.\nA combination of AV_PKT_FLAG values\nAV_CODEC_FLAG_*.\nA combination of AVFILTER_FLAG_*\nCombination of AV_PIX_FMT_FLAG_… flags.\nExtra flag information. Currently unused.\nAdditional information about the frame packing.\n&lt; flags such as drop frame, +24 hours support, …\nAV_CODEC_FLAG2_*\n&lt; Additional flags for avfilter internal use only.\nvideo: the pixel format, the value corresponds to enum …\nThe format of the coded data, corresponds to enum …\n&lt; agreed upon media format\nvideo: the pixel format, value corresponds to enum …\nFormat of the layer (DRM_FORMAT_*).\nFormat modifier applied to the object (DRM_FORMAT_MOD_*).\nList of supported formats (pixel or sample).\nThis field determines the state of the formats union. It …\n&lt; frame per second; must be consistent with the rate field\nFrame counter, set by libavcodec.\nVideo only, the frame rate of the input video. This field …\nAudio only. Audio frame size, if known. Required by some …\nNumber of samples per channel in an audio frame.\nVideo only. Number of frames per second, for streams with …\ndecoding: For codecs that store a framerate value in the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThis callback is called at the beginning of each frame to …\nThis callback is called at the beginning of each packet to …\nCallback to negotiate the pixel format. Decoding only, may …\nGlobal quality for codecs which cannot change it per frame.\nthe number of pictures in a group of pictures, or 0 for …\n&lt; filtergraph this filter belongs to\nThe filtergraph this segment is associated with. Set by …\n&lt; height           of pict, undefined when pict is not set\n&lt; agreed upon image height\nWidth and height of the block.\nSize of the frame reordering buffer in the decoder. For …\npicture width / height.\n&lt; height\nVideo only, the display dimensions of the input frames.\nRelative shift of the left and right images, which changes …\nHorizontal field of view, in degrees. Zero if unset.\nA reference to the AVHWDeviceContext describing the device …\nFor filters which will create hardware frames, sets the …\nA reference to the AVHWFramesContext describing the input …\nVideo with a hwaccel pixel format only. This should be a …\nHardware accelerator in use\nLegacy hardware accelerator context.\nBit set of AV_HWACCEL_FLAG_* flags, which affect hardware …\nqscale factor between P- and I-frames If &gt; 0 then the last …\nqscale offset between P and I-frames\nid\nCodec implemented by the hardware accelerator.\nIDCT algorithm, see FF_IDCT_* below.\ninterlaced DCT comparison function\nLists of supported formats / etc. supported by the input …\nFilter initialization function.\nAudio only. The amount of padding (in samples) inserted by …\nAudio only. The number of “priming” samples (padding) …\n&lt; array of input pads\nList of static inputs.\n&lt; array of pointers to input links\nName to be used for this filter instance.\ncustom inter quantization matrix Must be allocated with …\nPrivate context used for internal data.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nprecision of the intra DC coefficient - 8\ncustom intra quantization matrix Must be allocated with …\n&lt; the enabled state from the last expression evaluation\nSet by parser to 1 for key frames and 0 for non-key frames.\nminimum GOP size\nAn av_malloc()’ed string containing the pad label.\nPrevious frame byte position.\namount of previous MV predictors (2a+1 x 2a+1 square)\nArray of layers in the frame.\n&lt; length so far\n&lt; length so far\n&lt; number of coefficients in the vector\nEncoding level descriptor.\nAbsolute scale factor representing the level at which the …\nAmount to shift the luma height right to find the chroma …\nAmount to shift the luma width right to find the chroma …\nDescriptive name for the codec, meant to be more human …\nA more descriptive name for this codec. May be NULL.\nlow resolution decoding, 1-&gt; 1/2 size, 2-&gt;1/4 size\nluminance masking (0-&gt; disabled)\nmaximum number of B-frames between non-B-frames Note: The …\nMaximum bitrate of the stream, in bits per second. Zero if …\n&lt; maximum value for lowres supported by the decoder\nThe number of pixels per image to maximally accept.\nmaximum quantizer difference between frames\nThe number of samples per frame to maximally accept.\nmacroblock comparison function (not supported yet)\nmacroblock decision mode\nmaximum MB Lagrange multiplier\nminimum MB Lagrange multiplier\nmotion estimation comparison function\nmotion estimation prepass comparison function\nmaximum motion estimation search range in subpel units If …\nsubpixel motion estimation comparison function\nsubpel ME quality\n&lt; array indicating what media types(s), if any, a device …\nBit set of AV_CODEC_HW_CONFIG_METHOD_* flags, describing …\nMIME type(s) associated with the codec. May be NULL; if …\nMinimum bitrate of the stream, in bits per second. Zero if …\nMotion vector src_x = dst_x + motion_x / motion_scale …\nMotion vector src_x = dst_x + motion_x / motion_scale …\nNote: Value depends upon the compare function used for …\n&lt; short name for the profile\nName of the codec implementation. The name is globally …\nName of the codec described by this descriptor. It is …\nName of the hardware accelerated codec. The name is …\nFilter name. Must be non-NULL and unique among filters.\n&lt; name of this filter instance\nunique name for this input/output in the list\nAmount of entries in @ref coded_side_data.\n&lt; number of colors in pict, undefined when pict is not set\n&lt; The number of components each pixel has, (1-4)\n&lt; number of autodetected devices\nThe number of entries in the list of inputs.\n&lt; number of input pads\nNumber of layers in the frame.\n&lt; length of media_types array, 0 if device cannot provide …\nNumber of DRM objects making up this frame.\nThe number of entries in the list of outputs.\n&lt; number of output pads\nNumber of planes in the layer.\nNumber of entries in side_data_prefer_packet.\nMax number of threads allowed in this filter instance. If &lt;…\nMaximum number of threads used by filters in this graph. …\nnext input/input in the list, NULL if this is the last\nnoise vs. sse weight for the nsse comparison function\nIndex of the object containing this plane in the objects …\nArray of objects making up the frame.\n&lt; byte offset from starting packet start\nNumber of elements before the component of the first pixel.\nOffset within that object of this plane.\nfor some private data of the user\nPrivate data of the user, can be used to carry app …\nOpaque user data. May be set by the caller to an arbitrary …\nAVBufferRef for free use by the API user. FFmpeg will …\nOptions to be apllied to the filter.\nLists of supported formats / etc. supported by the output …\n&lt; array of output pads\nPicture number incremented in presentation or output order.\nList of static outputs.\n&lt; array of pointers to output links\np block masking (0-&gt; disabled)\nindex of the filt_ctx pad to use for linking\nIndicate whether a picture is coded as a frame, top field …\nPitch (linesize) of this plane.\nFor decoders, a hardware pixel format which that decoder …\nPixel format, see AV_PIX_FMT_xxx. May be set by the …\nSupported pixel format.\nEquivalent to { pix_fmt, AV_PIX_FMT_NONE } as pixels_list.\n&lt; @deprecated use avcodec_get_supported_config()\nA pointer to an array of admissible pixel formats delimited\nTimebase in which pkt_dts/pts and AVPacket.dts/pts are …\nWhich of the 4 planes contains the component.\nArray of planes in this layer.\n&lt; byte position in stream, -1 if unknown\nByte position of currently parsed frame in stream.\nposition of the top left corner in 1/16 pel for up to 3 …\nME prepass diamond size &amp; shape\nType of downmix preferred by the mastering engineer.\nFilter pre-initialization function\nWhich eye is the primary eye when rendering in 2D.\n&lt; private data for use by the filter\n&lt; AVClass for the private context\nA class for the private data, used to declare filter …\n&lt; size of private data to allocate for the filter\nMake the filter instance process a command.\nCodec-specific bitstream restrictions that the stream …\nprofile\n&lt; array of recognized profiles, or NULL if unknown, array …\nIf non-NULL, an array of profiles recognized for this …\nProperties of the stream that gets decoded\nCodec properties, a combination of AV_CODEC_PROP_* flags.\nPresentation timestamp in AVStream-&gt;time_base units; the …\n&lt; Same as packet pts, in AV_TIME_BASE\nPresentation delay of current frame in units of …\n&lt; amount of qscale smoothing over time (0.0-1.0)\n&lt; amount of qscale change between easy &amp; hard scenes …\nmaximum quantizer\nminimum quantizer\nQuery formats supported by the filter on its inputs and …\nSame as query_func(), except this function writes the …\n&lt; frame rate in rational form\ndecoder bitstream buffer size\nNumber of bits which should be loaded into the rc buffer …\nRatecontrol attempt to use, at maximum,  of what can be …\nmaximum bitrate\nminimum bitrate\nRatecontrol attempt to use, at least,  times the amount …\nratecontrol override, see RcOverride\nReady status of the filter. A non-0 value means that the …\nnumber of reference frames\nThis field is used for proper frame duration computation …\ndesired sample format\nVideo only. The aspect ratio (width / height) which a …\nsample aspect ratio (0 if unknown) That is the width of a …\n&lt; agreed upon sample aspect ratio\nVideo only, the sample (pixel) aspect ratio.\n&lt; sample format\nEquivalent to { sample_fmt, AV_SAMPLE_FMT_NONE } as …\n&lt; @deprecated use avcodec_get_supported_config()\nAudio only. The number of audio samples per second.\n&lt; samples per second\n&lt; samples per second\nAudio only, the audio sampling rate in samples per second.\nLists of supported sample rates, only for audio.\nAnalogous to pixels, but delimited by AV_SAMPLE_FMT_NONE …\n&lt; sws options to use for the auto-inserted scale filters\nA string containing a colon-separated list of key=value …\nAudio only. Number of samples to skip after a …\nNumber of samples to skip after a discontinuity\nNumber of least significant bits that must be shifted away …\nAdditional packet data that can be provided by the …\nDecoding only. May be set by the caller before …\n&lt; allocated memory\n&lt; allocated memory\nTotal size of the object.\n&lt; maximum allocated memory\n&lt; maximum allocated memory\nSkip processing alpha if supported by codec. Note that if …\nNumber of macroblock rows at the bottom which are skipped.\nSkip decoding for selected frames.\nSkip IDCT/dequantization for selected frames.\nSkip loop filtering for selected frames.\nNumber of macroblock rows at the top which are skipped.\nslice flags\nNumber of slices. Indicates number of picture …\nWhere the current macroblock comes from; negative value …\nspatial complexity masking (0-&gt; disabled)\n&lt; source filter\nAbsolute source position. Can be outside the frame area.\nAbsolute source position. Can be outside the frame area.\n&lt; output pad on the source filter\n&lt; timecode frame start (first base frame number)\npass2 encoding statistics input buffer Concatenated stuff …\npass1 encoding statistics output buffer\nNumber of elements between 2 horizontally consecutive …\n&lt; string so far\n&lt; string so far\nstrictly follow the standard (MPEG-4, …).\nCharacter encoding of the input subtitles file.\nSubtitles character encoding mode. Formats or codecs might …\nHeader containing style information for text subtitles. …\n&lt; @deprecated use avcodec_get_supported_config()\n&lt; @deprecated use avcodec_get_supported_config()\nAbsolute scale factor representing the nominal level of …\nAbsolute scale factor representing the nominal level of …\nNominal unaccelerated pixel format, see AV_PIX_FMT_xxx.\nAllocate SwrContext.\nAllocate SwrContext if needed and set/reset common …\nGenerate a channel mixing matrix.\nCloses the context so that swr_is_initialized() returns 0.\nConfigure or reconfigure the SwrContext using the …\nConvert audio.\nConvert the samples in the input AVFrame and write them to …\nDrops the specified number of output samples.\nFree the given SwrContext and set the pointer to NULL.\nGet the AVClass for SwrContext. It can be used in …\nGets the delay the next input sample will experience …\nFind an upper bound on the number of samples that the next …\nInitialize context after user parameters have been set. …\nInjects the specified number of silence samples.\nCheck whether an swr context has been initialized or not.\nConvert the next timestamp from input to output timestamps …\nSet a customized input channel mapping.\nActivate resampling compensation (“soft” …\nSet a customized remix matrix.\nReturn the swr build-time configuration.\nReturn the swr license.\nReturn the @ref LIBSWRESAMPLE_VERSION_INT constant.\nAllocate and return an uninitialized vector with length …\nAllocate an empty SwsContext. This must be filled and …\nConvert an 8-bit paletted frame into a frame with a color …\nConvert an 8-bit paletted frame into a frame with a color …\nFinish the scaling process for a pair of …\nInitialize the scaling process for a given pair of …\nFree the swscaler context swsContext. If swsContext is …\nCheck if context can be reused, otherwise reallocate a new …\nReturn a pointer to yuv&lt;-&gt;rgb coefficients for the given …\n@return A negative error code on error, non negative …\nAllocate and return an SwsContext. You need it to perform …\nReturn a normalized Gaussian curve used to filter stuff …\nGet the AVClass for swsContext. It can be used in …\nInitialize the swscaler context sws_context.\n@param[in]  pix_fmt the pixel format @return a positive …\nReturn a positive value if pix_fmt is a supported input …\nReturn a positive value if pix_fmt is a supported output …\nScale all the coefficients of a so that their sum equals …\nRequest a horizontal slice of the output data to be …\nGet the alignment required for slices\nScale the image slice in srcSlice and put the resulting …\nScale all the coefficients of a by the scalar value.\nScale source data from src and write the output to dst.\nIndicate that a horizontal slice of input data is …\n@param c the scaling context @param dstRange flag …\nReturn the libswscale build-time configuration.\nReturn the libswscale license.\n@defgroup libsws libswscale Color conversion and scaling …\ntemporary complexity masking (0-&gt; disabled)\n&lt; 0 terminated plain UTF-8 text\nthread count is used to decide how many independent tasks …\nWhich multithreading methods to use. Use of …\nType of multithreading being allowed/used. A combination of\nType of multithreading allowed for filters in this graph. …\nFor some codecs, the time base is closer to the field rate …\nTime base of the packet’s timestamps. In the future, …\nThis is the fundamental unit of time (in seconds) in terms …\nDefine the time base used by the PTS of the frames/samples …\nThe timebase to be used for the timestamps on the input …\nTrack replay gain in microbels (divide by 100000 to get …\nPeak track amplitude, with 100000 representing full scale …\nAudio only. The amount of padding (in samples) appended by …\nAudio only. The amount of padding (in samples) appended by …\ntrellis RD quantization\nType of codec implemented by the hardware accelerator.\n&lt; filter media type\nHow views are packed within the video.\nFilter uninitialization function.\n&lt; variable values for the enable expression\nThe delay between the time the packet this structure is …\nVideo only. Number of delayed frames.\nDetermines which views are packed.\n&lt; width            of pict, undefined when pict is not set\n&lt; agreed upon image width\nWidth and height of the block.\nA UTC timestamp, in microseconds, since Unix epoch (e.g, …\nwidth and height in 1/16 pel\nVideo only. The dimensions of the video frame in pixels.\npicture width / height.\nDimensions of the decoded video intended for presentation.\n&lt; width\nVideo only, the display dimensions of the input frames.\nWork around bugs in encoders which sometimes cannot be …\nGroup name of the codec implementation. This is a short …\n&lt; top left corner  of pict, undefined when pict is not set\n&lt; x coordinate of top left corner\n&lt; top left corner  of pict, undefined when pict is not set\n&lt; y coordinate of top left corner")